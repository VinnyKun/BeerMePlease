{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51cdb4d-a4b0-40da-8f39-d53f12cae77b",
   "metadata": {},
   "source": [
    "# Preprocessing for Content Model\n",
    "\n",
    "**Description:**  \n",
    "This notebook takes the combined and cleaned beer reviews and brewery metadata from `final_beers_reviews_breweries.csv`, aggregates all review texts for each beer into a single field. After aggregation, A BERT tokenizer to identify the most frequent tokens across each beer’s review corpus, reducing the feature space so that the downstream content autoencoder is not overwhelmed by a very high-dimensional vocabulary. The resulting file, `beer_content.csv`, containing `beer_id`, `name`, and `all_text` will be used as input to the content recommendation model.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Data Source:**  \n",
    "  `final_beers_reviews_breweries.csv` – contains user reviews joined with beer and brewery information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93455f0d-1b28-43ba-ad03-6b91374d1f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "inal Data Sample:\n",
      "              name state country                    style availability   abv  \\\n",
      "0  Older Viscosity    CA      US  American Imperial Stout     Rotating  12.0   \n",
      "1  Older Viscosity    CA      US  American Imperial Stout     Rotating  12.0   \n",
      "2  Older Viscosity    CA      US  American Imperial Stout     Rotating  12.0   \n",
      "3  Older Viscosity    CA      US  American Imperial Stout     Rotating  12.0   \n",
      "4  Older Viscosity    CA      US  American Imperial Stout     Rotating  12.0   \n",
      "\n",
      "                                               notes  beer_id     username  \\\n",
      "0  Imperial Stout aged for 12 months in new bourb...    34094        Sazz9   \n",
      "1  Imperial Stout aged for 12 months in new bourb...    34094  Amguerra305   \n",
      "2  Imperial Stout aged for 12 months in new bourb...    34094      TheGent   \n",
      "3  Imperial Stout aged for 12 months in new bourb...    34094         bobv   \n",
      "4  Imperial Stout aged for 12 months in new bourb...    34094      Tony210   \n",
      "\n",
      "         date  ...  look  smell  taste  feel  overall  score  name_brewery  \\\n",
      "0  2015-09-02  ...  4.50   4.50   4.25  4.50     4.25   4.35  Port Brewing   \n",
      "1  2017-06-21  ...  4.75   4.00   4.50  4.25     4.50   4.37  Port Brewing   \n",
      "2  2018-04-07  ...  4.00   4.50   4.50  3.75     4.50   4.40  Port Brewing   \n",
      "3  2018-04-03  ...  3.75   4.50   4.50  3.75     4.25   4.33  Port Brewing   \n",
      "4  2018-01-29  ...  4.50   4.25   4.50  4.50     4.50   4.44  Port Brewing   \n",
      "\n",
      "         city                                      notes_brewery  \\\n",
      "0  San Marcos  Owned by Port Brewing Company. Not affiliated ...   \n",
      "1  San Marcos  Owned by Port Brewing Company. Not affiliated ...   \n",
      "2  San Marcos  Owned by Port Brewing Company. Not affiliated ...   \n",
      "3  San Marcos  Owned by Port Brewing Company. Not affiliated ...   \n",
      "4  San Marcos  Owned by Port Brewing Company. Not affiliated ...   \n",
      "\n",
      "                      types  \n",
      "0  Brewery, Bar, Beer-to-go  \n",
      "1  Brewery, Bar, Beer-to-go  \n",
      "2  Brewery, Bar, Beer-to-go  \n",
      "3  Brewery, Bar, Beer-to-go  \n",
      "4  Brewery, Bar, Beer-to-go  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('final_beers_reviews_breweries.csv')\n",
    "    print(\"\\final Data Sample:\")\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading reviews.csv: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce4976d-7bc8-4916-a28e-5bfdf4fce0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614525 entries, 0 to 614524\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   name           614525 non-null  object \n",
      " 1   state          614525 non-null  object \n",
      " 2   country        614525 non-null  object \n",
      " 3   style          614525 non-null  object \n",
      " 4   availability   614525 non-null  object \n",
      " 5   abv            614525 non-null  float64\n",
      " 6   notes          614525 non-null  object \n",
      " 7   beer_id        614525 non-null  int64  \n",
      " 8   username       614525 non-null  object \n",
      " 9   date           614525 non-null  object \n",
      " 10  text           614525 non-null  object \n",
      " 11  look           614525 non-null  float64\n",
      " 12  smell          614525 non-null  float64\n",
      " 13  taste          614525 non-null  float64\n",
      " 14  feel           614525 non-null  float64\n",
      " 15  overall        614525 non-null  float64\n",
      " 16  score          614525 non-null  float64\n",
      " 17  name_brewery   614525 non-null  object \n",
      " 18  city           614525 non-null  object \n",
      " 19  notes_brewery  614525 non-null  object \n",
      " 20  types          614525 non-null  object \n",
      "dtypes: float64(7), int64(1), object(13)\n",
      "memory usage: 98.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a635e80a-281d-42e5-89db-1cbbe27525ec",
   "metadata": {},
   "source": [
    "## Aggregate Beer Metadata and Reviews\n",
    "\n",
    "This cell groups the data by `beer_id`, collecting core metadata (name, state, country, style, availability, ABV, brewery name, city) and computing the average score, while concatenating all individual review texts into a single `text` field for each beer, resulting in the consolidated DataFrame `dfbeers`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17a93b7-de29-488f-ae88-ffd9ee0d9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbeers = df.groupby('beer_id').agg({\n",
    "    'name': 'first',               # Beer name\n",
    "    'state': 'first',              # State\n",
    "    'country': 'first',            # Country\n",
    "    'style': 'first',              # Beer style\n",
    "    'availability': 'first',       # Availability info\n",
    "    'abv': 'first',                # ABV (assumes consistency)\n",
    "    'notes': 'first',              # First review note\n",
    "    'text': lambda x: ' '.join(x), # Join all reviews together\n",
    "    'score': 'mean',               # Average score\n",
    "    'name_brewery': 'first',       # Brewery name\n",
    "    'city': 'first',               # City\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef17efe-3e46-4f1e-84f4-bb2184c668fe",
   "metadata": {},
   "source": [
    "## Categorize ABV Levels\n",
    "\n",
    "This cell defines ABV bins ([0–5, 5–10, 10+]) with corresponding labels (`'low abv'`, `'medium abv'`, `'high abv'`) and uses `pd.cut` to create a new `abv_category` column in `dfbeers`, classifying each beer’s alcohol content into these categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b12f3d7-985b-42a3-b06e-787662e0e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bins = [0, 5, 10, np.inf]\n",
    "labels = ['low abv', 'medium abv', 'high abv']\n",
    "\n",
    "dfbeers['abv_category'] = pd.cut(dfbeers['abv'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7b1162-3a00-4bbe-8284-f4c6c85d2a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   beer_id       500 non-null    int64   \n",
      " 1   name          500 non-null    object  \n",
      " 2   state         500 non-null    object  \n",
      " 3   country       500 non-null    object  \n",
      " 4   style         500 non-null    object  \n",
      " 5   availability  500 non-null    object  \n",
      " 6   abv           500 non-null    float64 \n",
      " 7   notes         500 non-null    object  \n",
      " 8   text          500 non-null    object  \n",
      " 9   score         500 non-null    float64 \n",
      " 10  name_brewery  500 non-null    object  \n",
      " 11  city          500 non-null    object  \n",
      " 12  abv_category  500 non-null    category\n",
      "dtypes: category(1), float64(2), int64(1), object(9)\n",
      "memory usage: 47.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dfbeers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da60fa-1210-434c-9f52-81c087ad0125",
   "metadata": {},
   "source": [
    "## Create Combined Text Feature\n",
    "\n",
    "This cell concatenates key metadata fields (`name`, `style`, `country`, `notes`, `abv_category`) and the aggregated review text (`text`) into a single `all_text` column on `dfbeers`, producing a unified text representation for each beer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657ded7d-88aa-4da5-8096-41c38e98fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsConcat = ['name','style', 'country', 'notes', 'abv_category','text']\n",
    "dfbeers['all_text'] = dfbeers[colsConcat].astype(str).agg(' '.join, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da766e9-b37b-4922-9661-4726cdfb615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   beer_id       500 non-null    int64   \n",
      " 1   name          500 non-null    object  \n",
      " 2   state         500 non-null    object  \n",
      " 3   country       500 non-null    object  \n",
      " 4   style         500 non-null    object  \n",
      " 5   availability  500 non-null    object  \n",
      " 6   abv           500 non-null    float64 \n",
      " 7   notes         500 non-null    object  \n",
      " 8   text          500 non-null    object  \n",
      " 9   score         500 non-null    float64 \n",
      " 10  name_brewery  500 non-null    object  \n",
      " 11  city          500 non-null    object  \n",
      " 12  abv_category  500 non-null    category\n",
      " 13  all_text      500 non-null    object  \n",
      "dtypes: category(1), float64(2), int64(1), object(10)\n",
      "memory usage: 51.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfbeers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4cb9aa-8e7a-48a2-8783-5b1fdb00bee6",
   "metadata": {},
   "source": [
    "## Detect and Report Compute Device\n",
    "\n",
    "This cell checks for CUDA or MPS GPU support (falling back to CPU), sets the `device`, and prints the selected device along with GPU details if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a834996-8b21-417c-b7b5-439e314087a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Running on Apple Silicon GPU via MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\"  if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    idx = device.index or 0\n",
    "    print(\"GPU name: \", torch.cuda.get_device_name(idx))\n",
    "elif device.type == \"mps\":\n",
    "    print(\"Running on Apple Silicon GPU via MPS\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbb9ae-af59-4242-8e8c-d8920cf93cc5",
   "metadata": {},
   "source": [
    "## Initialize KeyBERT and Embedding Model\n",
    "\n",
    "This cell installs (if necessary) and imports KeyBERT and SentenceTransformer, loads the “all-MiniLM-L6-v2” BERT encoder onto the chosen `device`, and instantiates `kw_model` for keyword extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce78b40-828d-4380-bd77-fd3bba17a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vineeth/miniconda3/envs/deeplearn_course/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# installation step if necessary\n",
    "# pip install keybert\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# compact BERT model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "kw_model = KeyBERT(model=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62318da-d0f8-4f24-96c4-1c80ade90e80",
   "metadata": {},
   "source": [
    "## Extract Top BERT Keywords to Compact Text\n",
    "\n",
    "This cell merges standard English stop words with beer‑specific terms, defines `bertTopTerms` using KeyBERT to pull the top 150 keyphrases from each beer’s aggregated text, and applies it to `dfbeers[\"all_text\"]`, replacing the full text with a concise set of BERT‑derived keywords. \n",
    "\n",
    "<b>Do not re-run as it takes a few hours proceed to use the csv output attached in the autoencoder model</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0955f9-7432-49f4-b2ee-279c3a6eafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "non_taste_stop = {\n",
    "    \"us\", \"ca\", \"beer\", \"head\", \"taste\", \"pours\", \"like\", \"s\", \"t\", \"year\", \"round\", \"abv\",'compared','10','11', '12',\n",
    "    \"availability\", \"yearround\", \"us\",\"ca\",\"just\",\"really\",\"overall\",\"bottle\",\"good\", \"nice\", 'brewery',\n",
    "    'brewing', 'brews', 'brew', 'style','drink', 'drinks', 'drinking', 'tastes', 'tasted', 'enjoy', 'enjoyable', 'okay',\n",
    "    'recommended','appearance', 'looking','great', 'decent', 'pretty', 'amazing', 'excellent', 'best', 'favorite',\n",
    "    'interesting', 'quality', 'look' 'beautiful', 'looks', 'look', 'exceptional', 'outstanding', 'slightly','expected',\n",
    "    'definitely', 'pleasant', 'recommend', 'slightly', \"awesome\", \"fantastic\", \"beautiful\", \"solid\", \"make\", \"review\",\n",
    "    'delightful','fine','quite','mix','makes','type','curious','liked','average','perfect','way','does','try','buy',\n",
    "    'following','enjoyed','somewhat','definitely','wonderful','wonderfully','making','experience','specific','pure','odd',\n",
    "    'impression','love', 'try', 'tried', 'extremely', 'alcoholic', 'appreciate', 'attractive', 'bad', 'better','compare',\n",
    "    'especially', 'bold', 'characteristics', 'choice', 'color', 'colored','totally', 'unusual', 'usual', 'particular',\n",
    "    'generally', 'different', 'drinker', 'finest', 'flavoring', 'flavours', 'kind','flavored', 'flavour', \n",
    "    'general', 'normal', 'opinion', 'pleasantly', 'prefer', 'regular','sample','gives','usually', 'brewed','honestly',\n",
    "    'slight', 'smell', 'smells', 'smoothest', 'styles', 'traditional', 'typical', 'unique', 'worthy','breweries',\n",
    "    'concerned', 'consider', 'considering', '12oz', '22oz', '2x', '750ml', '22','actually','absolutely', 'amazingly', \n",
    "    'exceptionally', 'extraordinary','fabulously', 'fantastically', 'incredibly', 'perfectly','remarkably', 'spectacular',\n",
    "    'stunning', 'truly', 'totally','wonderfully', 'delightfully', 'deliciously', 'fascinating','exciting', 'fantastic',\n",
    "    'disappointing','phenomenal','satisfying','enjoying','experienced', 'bottled', 'bottles', 'highly', 'surprisingly'\n",
    "    'intriguing', 'noticeable', 'liking', 'lovely', 'impressed', 'impressive','intriguing', 'similar','remarkable',\n",
    "    'reviewed','reviews', 'fairly','qualities','beautifully','drank','tastey', 'terrific','flavoured','surprisingly'\n",
    "    'incredible','brewer','apparent'\n",
    "}\n",
    "\n",
    "stopwords = list(ENGLISH_STOP_WORDS.union(non_taste_stop))\n",
    "\n",
    "def bertTopTerms(doc, top_n = 150):\n",
    "    kws = kw_model.extract_keywords(\n",
    "        doc,\n",
    "        keyphrase_ngram_range=(1,2),\n",
    "        stop_words=stopwords,\n",
    "        top_n=top_n\n",
    "    )\n",
    "    return \" \".join(term for term, score in kws)\n",
    "\n",
    "dfbeers[\"all_text\"] = dfbeers[\"all_text\"].apply(lambda txt: bertTopTerms(txt, top_n=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81774bf-114c-4236-9604-6d532490b9d4",
   "metadata": {},
   "source": [
    "## Experimental TF‑IDF Keyword Extraction (Unused)\n",
    "\n",
    "This cell experiments with a TF‑IDF Vectorizer to select the most frequent terms from `all_text` as an alternative to BERT/KeyBERT, but this approach was ultimately not adopted in the final content preprocessing pipeline as it was selecting from the whole corpus rather than per beer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9715b-f52e-46b2-ae41-e3b4cfa79011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative faster but results in too many similarities hence UNUSED in final model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "token_pattern = r'\\b[a-z]{4,}\\b'\n",
    "vec = TfidfVectorizer(stop_words=list(stopwords),\n",
    "                      token_pattern=token_pattern,\n",
    "                      max_features=2000,\n",
    "                      max_df=0.8)\n",
    "tf = vec.fit_transform(dfbeers['all_text'])\n",
    "feat = vec.get_feature_names_out()\n",
    "\n",
    "def top_tfidf_terms(row, N=100): \n",
    "    arr = row.toarray().ravel()\n",
    "    idxs = arr.argsort()[-N:][::-1]\n",
    "    return \" \".join(feat[i] for i in idxs)\n",
    "\n",
    "# UNUSED\n",
    "# dfbeers['all_text'] = [top_tfidf_terms(r, 150) for r in tf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2854d0-887a-40f1-82c5-904df4122576",
   "metadata": {},
   "source": [
    "## Summarize Token Counts per Beer\n",
    "\n",
    "This cell splits each beer’s `all_text` into tokens and prints the average, median, and 90th percentile token counts to assess the length distribution of the processed text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf9a24d-2988-4e49-9afa-51e1a4f9d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per beer: 299.5\n",
      "Median tokens per beer:  300.0\n",
      "90th percentile tokens:  300.0\n"
     ]
    }
   ],
   "source": [
    "# How many tokens (words) per beer on average?\n",
    "import numpy as np\n",
    "token_counts = dfbeers['all_text'].str.split().str.len()\n",
    "print(\"Average tokens per beer:\", token_counts.mean().round(1))\n",
    "print(\"Median tokens per beer: \", token_counts.median())\n",
    "print(\"90th percentile tokens: \", np.percentile(token_counts, 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db6c68-8b41-40c9-9ee8-22c59e87a073",
   "metadata": {},
   "source": [
    "## Export Final Content DataFrame\n",
    "\n",
    "This cell selects the `beer_id`, `name`, and compressed `all_text` columns from `dfbeers` and writes them to `beer_content.csv`, producing the final dataset for the content recommendation model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3805ce5-a2ba-4c27-84a5-a3f67dceccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dfbeers[['beer_id', 'name', 'all_text']]\n",
    "output.to_csv(\"beer_content.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d8820-ca26-438f-bf58-381025dda073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
