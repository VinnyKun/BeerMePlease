{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8596f103-0541-47b9-8f30-2ad2f76aa3cf",
   "metadata": {},
   "source": [
    "# Collaborative Filtering â€“ Score-Only Model\n",
    "\n",
    "This notebook begins the modeling phase of the beer recommender system by implementing a basic collaborative filtering approach based solely on user-item interactions, specifically the review `score`.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The primary goal of this stage is to:\n",
    "- Build a collaborative filtering model using **only user IDs and beer IDs**, along with their corresponding **review scores**.\n",
    "- Evaluate how well a latent factor model can learn user preferences and item characteristics using **implicit patterns in rating behavior**.\n",
    "- Establish a baseline model to be enhanced in future iterations with additional beer metadata (e.g., ABV, style, availability) for hybrid recommendations.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- Construct a **user-beer matrix** from the cleaned review data.\n",
    "- Train a **matrix factorization model** (e.g., using PyTorch or an embedding-based MLP).\n",
    "- Evaluate the model using metrics such as RMSE and top-k recommendation quality.\n",
    "\n",
    "This foundational model serves as a benchmark against which hybrid models incorporating beer content features will be compared in later notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed9197f-1659-47e6-a76d-ce782bc28fb4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab2ced6-3b2a-4a2f-aa5e-62cad41af3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device found\")\n",
    "\n",
    "\n",
    "# Loading Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('final_beers_reviews_breweries.csv')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading reviews.csv: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27abdbd-60bf-49c9-8e87-d813629bf87f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985305f-2620-4617-8ecb-fe367a7977c4",
   "metadata": {},
   "source": [
    "### Feature Normalization\n",
    "\n",
    "To prepare the rating-related attributes for collaborative filtering models, the following review features were scaled to a [0, 1] range using **MinMax normalization**:\n",
    "- `look`\n",
    "- `smell`\n",
    "- `taste`\n",
    "- `feel`\n",
    "- `overall`\n",
    "- `score`\n",
    "\n",
    "This normalization ensures that all rating dimensions contribute equally during training, preventing attributes with larger original scales from disproportionately influencing the learning process.\n",
    "\n",
    "#### Post-Normalization Summary:\n",
    "- All normalized features have a **minimum of 0.0** and a **maximum of 1.0**.\n",
    "- The distribution remains centered around **0.75**, reflecting the original skew of the review scores toward higher ratings.\n",
    "\n",
    "This step sets a consistent numerical foundation for training latent factor models such as matrix factorization or embedding-based recommenders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c4c69b-8038-4c44-9b58-3c6542542963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abv</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>look</th>\n",
       "      <th>smell</th>\n",
       "      <th>taste</th>\n",
       "      <th>feel</th>\n",
       "      <th>overall</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "      <td>614525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.582153</td>\n",
       "      <td>13682.230450</td>\n",
       "      <td>0.754612</td>\n",
       "      <td>0.736018</td>\n",
       "      <td>0.755178</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>0.751018</td>\n",
       "      <td>0.748170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.353999</td>\n",
       "      <td>20065.492805</td>\n",
       "      <td>0.142259</td>\n",
       "      <td>0.159482</td>\n",
       "      <td>0.163359</td>\n",
       "      <td>0.155050</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.140153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.600000</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.200000</td>\n",
       "      <td>2137.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>21300.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>148052.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 abv        beer_id           look          smell  \\\n",
       "count  614525.000000  614525.000000  614525.000000  614525.000000   \n",
       "mean        7.582153   13682.230450       0.754612       0.736018   \n",
       "std         2.353999   20065.492805       0.142259       0.159482   \n",
       "min         2.500000       6.000000       0.000000       0.000000   \n",
       "25%         5.600000     689.000000       0.687500       0.625000   \n",
       "50%         7.200000    2137.000000       0.750000       0.750000   \n",
       "75%         9.100000   21300.000000       0.875000       0.875000   \n",
       "max        18.000000  148052.000000       1.000000       1.000000   \n",
       "\n",
       "               taste           feel        overall          score  \n",
       "count  614525.000000  614525.000000  614525.000000  614525.000000  \n",
       "mean        0.755178       0.738499       0.751018       0.748170  \n",
       "std         0.163359       0.155050       0.158492       0.140153  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.687500       0.625000       0.687500       0.687500  \n",
       "50%         0.750000       0.750000       0.750000       0.770000  \n",
       "75%         0.875000       0.875000       0.875000       0.837500  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['look', 'smell', 'taste', 'feel', 'overall', 'score']] = scaler.fit_transform(\n",
    "    df[[ 'look', 'smell', 'taste', 'feel', 'overall', 'score']]\n",
    ")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef40b9f-8f16-4828-92b8-b653c95d6f56",
   "metadata": {},
   "source": [
    "### User and Item Index Mapping\n",
    "\n",
    "To prepare the dataset for collaborative filtering with matrix-based models, each unique user and beer was assigned a numeric index:\n",
    "\n",
    "- **User Mapping**: `username` values were mapped to a new `userIndex` column using a unique integer for each user.\n",
    "- **Beer Mapping**: `beer_id` values were mapped to a `beerIndex` column similarly.\n",
    "\n",
    "This indexing allows for efficient embedding lookup during model training.\n",
    "\n",
    "- **Unique Users**: 15,894\n",
    "- **Unique Beers**: 500  \n",
    "  *(Note: This aligns with the earlier filtering to include only the top 500 most-reviewed beers.)*\n",
    "\n",
    "### Train-Validation Split\n",
    "\n",
    "The dataset was randomly split into:\n",
    "- **Training Set**: 80% (491,620 rows)\n",
    "- **Validation Set**: 20% (122,905 rows)\n",
    "\n",
    "This split enables model training and unbiased evaluation on held-out data before proceeding to test or production deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571ad882-b35b-47f7-aa15-c3b23f249737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 15894\n",
      "Number of unique beers: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create mapping dictionaries for users and beers\n",
    "users = df['username'].unique()\n",
    "userIndexMap = {user: idx for idx, user in enumerate(users)}\n",
    "\n",
    "beers = df['beer_id'].unique()\n",
    "beerIndexMap = {beer: idx for idx, beer in enumerate(beers)}\n",
    "\n",
    "# Map the original columns to new index columns\n",
    "df['userIndex'] = df['username'].map(userIndexMap)\n",
    "df['beerIndex'] = df['beer_id'].map(beerIndexMap)\n",
    "\n",
    "print(\"Number of unique users:\", len(userIndexMap))\n",
    "print(\"Number of unique beers:\", len(beerIndexMap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eee6d16-7c48-4050-99fb-f79c0b15838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (491620, 23)\n",
      "Validation set shape: (122905, 23)\n"
     ]
    }
   ],
   "source": [
    "# Split the data (e.g., 80% training, 20% validation)\n",
    "trainDf, valDf = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", trainDf.shape)\n",
    "print(\"Validation set shape:\", valDf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16dde0-5de1-495f-b1c5-107053c9afae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333bd4f-af86-4d44-a20e-9589a98297aa",
   "metadata": {},
   "source": [
    "### PyTorch Dataset and DataLoader Preparation\n",
    "\n",
    "To enable efficient training of the collaborative filtering model in PyTorch, a custom dataset class `BeerDataset` was implemented. This class wraps the training and validation DataFrames and provides:\n",
    "\n",
    "- **user**: Encoded user index (`userIndex`)\n",
    "- **beer**: Encoded item index (`beerIndex`)\n",
    "- **score**: Normalized review score as the target\n",
    "\n",
    "Each sample is returned as a dictionary containing tensors for user, beer, and score, making it suitable for mini-batch training.\n",
    "\n",
    "#### DataLoaders\n",
    "The dataset is loaded into PyTorch `DataLoader`s:\n",
    "- **Training Loader** (`trainLoader`): Uses a batch size of 256 and shuffling enabled to randomize batches during training.\n",
    "- **Validation Loader** (`valLoader`): Uses the same batch size but no shuffling, preserving the order for evaluation.\n",
    "\n",
    "These components prepare the dataset for input into an embedding-based collaborative filtering model that will learn latent user and beer representations from the interaction data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc9e86b-746d-41bd-8307-28c23683161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BeerDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = df['userIndex'].values\n",
    "        self.beer_ids = df['beerIndex'].values\n",
    "        self.scores = df['score'].values.astype('float32')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.scores)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user': torch.tensor(self.user_ids[idx], dtype=torch.long),\n",
    "            'beer': torch.tensor(self.beer_ids[idx], dtype=torch.long),\n",
    "            'score': torch.tensor(self.scores[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "trainDataset = BeerDataset(trainDf)\n",
    "valDataset = BeerDataset(valDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a73f07-694d-4b31-b695-abfe96f361db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainLoader = DataLoader(trainDataset, batch_size=256, shuffle=True)\n",
    "valLoader = DataLoader(valDataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199de313-5437-4d4b-8485-be29749da5c2",
   "metadata": {},
   "source": [
    "### Model Architecture â€“ Score-Only Recommender\n",
    "\n",
    "The collaborative filtering model is implemented using a neural network architecture that leverages **user and item embeddings** to learn latent preferences and item characteristics.\n",
    "\n",
    "#### Key Components:\n",
    "\n",
    "- **Embedding Layers**:\n",
    "  - `user_embedding`: Learns a dense vector for each user.\n",
    "  - `beer_embedding`: Learns a dense vector for each beer.\n",
    "  \n",
    "- **Bias Terms**:\n",
    "  - `user_bias` and `beer_bias`: Capture individual user and beer bias.\n",
    "  - `global_bias`: A learnable scalar capturing the overall average rating tendency.\n",
    "\n",
    "- **Multi-Layer Perceptron (MLP)**:\n",
    "  - Concatenates the user and beer embeddings.\n",
    "  - Passes the combined vector through two fully connected layers with ReLU activation to capture non-linear interactions.\n",
    "  - Outputs a base prediction (`base_pred`) for the rating.\n",
    "\n",
    "- **Final Prediction**:\n",
    "  \\[\n",
    "  \\hat{r}_{u,i} = \\text{base\\_pred} + b_u + b_i + b\n",
    "  \\]\n",
    "  Where:\n",
    "  - \\( \\hat{r}_{u,i} \\) is the predicted rating for user *u* and beer *i*\n",
    "  - \\( b_u \\), \\( b_i \\), and \\( b \\) are the user, item, and global biases, respectively\n",
    "\n",
    "#### Optimization:\n",
    "\n",
    "- **Loss Function**: Mean Squared Error (MSE) is used to penalize differences between predicted and actual scores.\n",
    "- **Optimizer**: Adam optimizer is employed with a learning rate of **0.0025**.\n",
    "\n",
    "The model is designed to run on GPU if available, ensuring faster training on large datasets. This architecture serves as the baseline for later enhancements that incorporate beer metadata (e.g., style, ABV) into the recommendation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1390502-b7b0-4910-9107-75ae43ef0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_beers, embedding_dim=32):\n",
    "        super(Recommender, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.beer_embedding = nn.Embedding(num_beers, embedding_dim)\n",
    "        \n",
    "        #insert bias terms\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.beer_bias = nn.Embedding(num_beers, 1)\n",
    "        self.global_bias = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        #MLP for combined embeddings\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, user, beer):\n",
    "        user_emb = self.user_embedding(user)   # Shape: (batch_size, embedding_dim)\n",
    "        beer_emb = self.beer_embedding(beer)     # Shape: (batch_size, embedding_dim)\n",
    "        # Dot product of the embeddings gives a predicted rating\n",
    "        #rating = (user_emb * beer_emb).sum(dim=1)\n",
    "\n",
    "        #Concatenate the embeddings for MLP\n",
    "        x = torch.cat([user_emb, beer_emb], dim=1)\n",
    "\n",
    "        #Predict base scare using MLP\n",
    "        base_pred = self.fc_layers(x).squeeze()\n",
    "        \n",
    "        #modify the forward method\n",
    "        \n",
    "        user_b = self.user_bias(user).squeeze() #insert bias contributions\n",
    "        beer_b = self.beer_bias(beer).squeeze()\n",
    "        \n",
    "        rating = base_pred + user_b + beer_b + self.global_bias #global bias + user bias + self.global_bias\n",
    "\n",
    "        return rating\n",
    "\n",
    "# Initialize model parameters\n",
    "userCount = len(userIndexMap)\n",
    "beerCount = len(beerIndexMap)\n",
    "model = Recommender(userCount, beerCount, embedding_dim=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5356013a-8a61-4e42-b239-8410095b036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af357307-c2a2-43da-83b8-1b4329aabc39",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d5deb-5273-4acc-a175-7632e6e6ccdb",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "The recommender model was trained over **30 epochs** using the **Adam optimizer** and **Mean Squared Error (MSE)** as the loss function. Each mini-batch contained 256 samples drawn from the training set.\n",
    "\n",
    "#### Training Configuration:\n",
    "- **Optimizer**: Adam\n",
    "- **Learning Rate**: 0.0025 (heuristically chosen)\n",
    "- **Loss Function**: MSELoss\n",
    "- **Epochs**: 30\n",
    "- **Batch Size**: 256\n",
    "- **Hardware**: GPU-accelerated (if available)\n",
    "\n",
    "#### Observations:\n",
    "- Initial loss started at approximately **0.37**, quickly converging below **0.02** within a few epochs.\n",
    "- Final epoch loss reached approximately **0.0113**, indicating strong convergence.\n",
    "- The training loss curve shows a consistent downward trend, demonstrating effective learning without overfitting during the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c8fade-737f-493e-b8ed-70a7ab0707cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0025) # arbritary selection of lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad6b18d-d929-41ed-8144-0989bf19c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.3695\n",
      "Epoch 2/30, Loss: 0.0362\n",
      "Epoch 3/30, Loss: 0.0213\n",
      "Epoch 4/30, Loss: 0.0182\n",
      "Epoch 5/30, Loss: 0.0167\n",
      "Epoch 6/30, Loss: 0.0157\n",
      "Epoch 7/30, Loss: 0.0151\n",
      "Epoch 8/30, Loss: 0.0146\n",
      "Epoch 9/30, Loss: 0.0141\n",
      "Epoch 10/30, Loss: 0.0139\n",
      "Epoch 11/30, Loss: 0.0136\n",
      "Epoch 12/30, Loss: 0.0134\n",
      "Epoch 13/30, Loss: 0.0132\n",
      "Epoch 14/30, Loss: 0.0130\n",
      "Epoch 15/30, Loss: 0.0128\n",
      "Epoch 16/30, Loss: 0.0127\n",
      "Epoch 17/30, Loss: 0.0126\n",
      "Epoch 18/30, Loss: 0.0125\n",
      "Epoch 19/30, Loss: 0.0124\n",
      "Epoch 20/30, Loss: 0.0123\n",
      "Epoch 21/30, Loss: 0.0121\n",
      "Epoch 22/30, Loss: 0.0120\n",
      "Epoch 23/30, Loss: 0.0119\n",
      "Epoch 24/30, Loss: 0.0119\n",
      "Epoch 25/30, Loss: 0.0118\n",
      "Epoch 26/30, Loss: 0.0117\n",
      "Epoch 27/30, Loss: 0.0116\n",
      "Epoch 28/30, Loss: 0.0115\n",
      "Epoch 29/30, Loss: 0.0114\n",
      "Epoch 30/30, Loss: 0.0113\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRUElEQVR4nO3df1xUdb4/8NfMMDMww4/8CZiIlCaav0EFzMxcMOyHaV7JCvWma4R6I+q7V9JKzc3qlqLlj9xKcreSbc2sGyVjaWpo+QOsNm3dm4oppOi6AyLDMPP5/gFzYJwBmXFmziCv5+Py0PnMZz7zOW9O6+ue8znnKIQQAkRERETtkFLuCRARERHJhUGIiIiI2i0GISIiImq3GISIiIio3WIQIiIionaLQYiIiIjaLQYhIiIiarcYhIiIiKjdYhAiIiKidotBiOgaKRSKVv3s3Lnzmr5n0aJFUCgUbn12586dHpnDtXz33/72N59/tzv27duH//iP/0BkZCQ0Gg0iIiIwefJk7N27V+6pOThx4kSL+9yiRYvkniJ69uyJe+65R+5pEDUrQO4JELV1V/4D+cILL2DHjh346quv7Nr79et3Td8za9Ys3HXXXW59dujQodi7d+81z+F69/rrryMrKwvDhw/HK6+8gujoaJSWlmL16tW47bbbsHLlSsydO1fuaTqYN28eHnroIYf27t27yzAboraFQYjoGiUkJNi97tKlC5RKpUP7laqrq6HT6Vr9Pd27d3f7H7bQ0NCrzqe9++abb5CVlYXx48djy5YtCAho/J/HBx98EBMnTsQTTzyBIUOGYOTIkT6b1+XLlxEYGNji0cAePXrw90vkJp4aI/KBO+64A/3798euXbuQlJQEnU6HRx99FACQn5+PlJQUREZGIigoCH379sX8+fNx6dIluzGcnRqznXb44osvMHToUAQFBSE2NhbvvPOOXT9np8ZmzJiB4OBg/POf/8T48eMRHByMqKgoPPXUUzCZTHaf//XXXzF58mSEhITghhtuwMMPP4z9+/dDoVAgLy/PIzX68ccfMWHCBHTo0AGBgYEYPHgw3n33Xbs+VqsVS5cuRZ8+fRAUFIQbbrgBAwcOxMqVK6U+586dw+zZsxEVFQWtVosuXbpg5MiR2L59e4vfv2zZMigUCqxdu9YuBAFAQEAA1qxZA4VCgZdeegkA8PHHH0OhUODLL790GGvt2rVQKBT4/vvvpbYDBw7gvvvuQ8eOHREYGIghQ4bgr3/9q93n8vLyoFAoUFhYiEcffRRdunSBTqdz+H24w7YP7t69GwkJCQgKCsKNN96IZ599FhaLxa7vhQsXkJmZiRtvvBEajQY33XQTFixY4DAPq9WK119/HYMHD5Z+HwkJCfjkk08cvv9q+2h1dTWefvppxMTEIDAwEB07dkR8fDw++OCDa952opbwiBCRj5SVleGRRx7BH/7wB7z44otQKuv//5Bjx45h/PjxyMrKgl6vx9GjR/Hyyy/ju+++czi95szhw4fx1FNPYf78+QgPD8dbb72FmTNnolevXrj99ttb/KzZbMZ9992HmTNn4qmnnsKuXbvwwgsvICwsDM899xwA4NKlSxgzZgwuXLiAl19+Gb169cIXX3yBtLS0ay9Kg59//hlJSUno2rUrVq1ahU6dOuEvf/kLZsyYgd9++w1/+MMfAACvvPIKFi1ahIULF+L222+H2WzG0aNHcfHiRWms9PR0HDp0CH/84x9xyy234OLFizh06BDOnz/f7PdbLBbs2LED8fHxzR51i4qKQlxcHL766itYLBbcc8896Nq1KzZs2ICxY8fa9c3Ly8PQoUMxcOBAAMCOHTtw1113YcSIEVi3bh3CwsKwadMmpKWlobq6GjNmzLD7/KOPPoq7774bf/7zn3Hp0iWo1eoW62e1WlFXV+fQfmWgKy8vx4MPPoj58+djyZIl+Oyzz7B06VL861//whtvvAEAqKmpwZgxY/B///d/WLx4MQYOHIjdu3dj2bJlKCkpwWeffSaNN2PGDPzlL3/BzJkzsWTJEmg0Ghw6dAgnTpyw+97W7KPZ2dn485//jKVLl2LIkCG4dOkSfvzxxxZ/b0QeIYjIo6ZPny70er1d2+jRowUA8eWXX7b4WavVKsxms/j6668FAHH48GHpveeff15c+Z9sdHS0CAwMFCdPnpTaLl++LDp27Cgee+wxqW3Hjh0CgNixY4fdPAGIv/71r3Zjjh8/XvTp00d6vXr1agFAfP7553b9HnvsMQFAbNiwocVtsn33hx9+2GyfBx98UGi1WlFaWmrXnpqaKnQ6nbh48aIQQoh77rlHDB48uMXvCw4OFllZWS32uVJ5ebkAIB588MEW+6WlpQkA4rfffhNCCJGdnS2CgoKk+QkhxE8//SQAiNdff11qi42NFUOGDBFms9luvHvuuUdERkYKi8UihBBiw4YNAoCYNm1aq+Z9/PhxAaDZn927d0t9bfvg1q1b7cb4/e9/L5RKpbQPrVu3zul+8fLLLwsAorCwUAghxK5duwQAsWDBghbn2Np9tH///uL+++9v1XYTeRJPjRH5SIcOHXDnnXc6tP/yyy946KGHEBERAZVKBbVajdGjRwMAjhw5ctVxBw8ejB49ekivAwMDccstt+DkyZNX/axCocC9995r1zZw4EC7z3799dcICQlxWKg9derUq47fWl999RXGjh2LqKgou/YZM2agurpaWpA+fPhwHD58GJmZmdi2bRuMRqPDWMOHD0deXh6WLl2Kffv2wWw2e2yeQggAkE5RPvroo7h8+TLy8/OlPhs2bIBWq5UWL//zn//E0aNH8fDDDwMA6urqpJ/x48ejrKwMP//8s933PPDAAy7N64knnsD+/fsdfgYPHmzXLyQkBPfdd59d20MPPQSr1Ypdu3YBqP9d6PV6TJ482a6f7aiV7VTg559/DgCYM2fOVefXmn10+PDh+PzzzzF//nzs3LkTly9fbt3GE10jBiEiH4mMjHRoq6qqwqhRo/Dtt99i6dKl2LlzJ/bv34+PPvoIAFr1j0GnTp0c2rRabas+q9PpEBgY6PDZmpoa6fX58+cRHh7u8Flnbe46f/680/p069ZNeh8AcnJy8Oqrr2Lfvn1ITU1Fp06dMHbsWBw4cED6TH5+PqZPn4633noLiYmJ6NixI6ZNm4by8vJmv79z587Q6XQ4fvx4i/M8ceIEdDodOnbsCAC49dZbMWzYMGzYsAFA/Sm2v/zlL5gwYYLU57fffgMAPP3001Cr1XY/mZmZAICKigq773FWi5Z0794d8fHxDj/BwcF2/Zz9ziIiIgA01vj8+fOIiIhwWI/WtWtXBAQESP3OnTsHlUolfb4lrdlHV61ahf/+7//Gxx9/jDFjxqBjx464//77cezYsauOT3QtGISIfMTZVT9fffUVzpw5g3feeQezZs3C7bffjvj4eISEhMgwQ+c6deok/WPeVEvBwp3vKCsrc2g/c+YMgPqgAtSvecnOzsahQ4dw4cIFfPDBBzh16hTGjRuH6upqqW9ubi5OnDiBkydPYtmyZfjoo48c1uE0pVKpMGbMGBw4cAC//vqr0z6//vorDh48iDvvvBMqlUpq/8///E/s27cPR44cwRdffIGysjL853/+p/S+be45OTlOj9o4O3Lj7v2irqal36MtrNh+37ajXzZnz55FXV2dtD1dunSBxWLx2H6g1+uxePFiHD16FOXl5Vi7di327dvncMSSyNMYhIhkZPsHT6vV2rW/+eabckzHqdGjR6OyslI6FWKzadMmj33H2LFjpVDY1MaNG6HT6ZxeGn7DDTdg8uTJmDNnDi5cuOCwQBeov6x87ty5SE5OxqFDh1qcQ05ODoQQyMzMdLiKymKx4PHHH4cQAjk5OXbvTZ06FYGBgcjLy0NeXh5uvPFGpKSkSO/36dMHvXv3xuHDh50etfFl8K2srHS4ouv999+HUqmUFi2PHTsWVVVV+Pjjj+36bdy4UXofAFJTUwHUXyHnaeHh4ZgxYwamTp2Kn3/+WQq5RN7Aq8aIZJSUlIQOHTogIyMDzz//PNRqNd577z0cPnxY7qlJpk+fjhUrVuCRRx7B0qVL0atXL3z++efYtm0bAEhXv13Nvn37nLaPHj0azz//PP73f/8XY8aMwXPPPYeOHTvivffew2effYZXXnkFYWFhAIB7770X/fv3R3x8PLp06YKTJ08iNzcX0dHR6N27N/79739jzJgxeOihhxAbG4uQkBDs378fX3zxBSZNmtTi/EaOHInc3FxkZWXhtttuw9y5c9GjRw/phorffvstcnNzkZSUZPe5G264ARMnTkReXh4uXryIp59+2qEmb775JlJTUzFu3DjMmDEDN954Iy5cuIAjR47g0KFD+PDDD1tVw+aUlpY6rW+XLl1w8803S687deqExx9/HKWlpbjllltQUFCAP/3pT3j88celNTzTpk3D6tWrMX36dJw4cQIDBgzAnj178OKLL2L8+PH43e9+BwAYNWoU0tPTsXTpUvz222+45557oNVqUVxcDJ1Oh3nz5rm0DSNGjMA999yDgQMHokOHDjhy5Aj+/Oc/IzEx0aX7bRG5TN612kTXn+auGrv11lud9i8qKhKJiYlCp9OJLl26iFmzZolDhw45XJHV3FVjd999t8OYo0ePFqNHj5ZeN3fV2JXzbO57SktLxaRJk0RwcLAICQkRDzzwgCgoKHB6FdKVbN/d3I9tTj/88IO49957RVhYmNBoNGLQoEEOV6S99tprIikpSXTu3FloNBrRo0cPMXPmTHHixAkhhBA1NTUiIyNDDBw4UISGhoqgoCDRp08f8fzzz4tLly61OE+bvXv3ismTJ4vw8HAREBAgunbtKiZNmiSKioqa/UxhYaG0Pf/4xz+c9jl8+LCYMmWK6Nq1q1Cr1SIiIkLceeedYt26dVIf21Vj+/fvb9Vcr3bV2MMPPyz1te2DO3fuFPHx8UKr1YrIyEjxzDPPOFzNdv78eZGRkSEiIyNFQECAiI6OFjk5OaKmpsaun8ViEStWrBD9+/cXGo1GhIWFicTERPHpp59KfVq7j86fP1/Ex8eLDh06CK1WK2666Sbx5JNPioqKilbVgshdCiGuOBFMRNQKL774IhYuXIjS0lI+yqENuOOOO1BRUYEff/xR7qkQ+RWeGiOiq7LdbC82NhZmsxlfffUVVq1ahUceeYQhiIjaNAYhIroqnU6HFStW4MSJEzCZTOjRowf++7//GwsXLpR7akRE14SnxoiIiKjd4uXzRERE1G4xCBEREVG7xSBERERE7RYXSzthtVpx5swZhISEeO1W90RERORZQghUVlaiW7durb7ZK4OQE2fOnHF4CjYRERG1DadOnWr1rT0YhJywPffn1KlTCA0N9ejYZrMZhYWFSElJgVqt9ujY1zPWzXWsmXtYN/ewbu5h3VzXUs2MRiOioqJcen4fg5ATttNhoaGhXglCOp0OoaGh3OldwLq5jjVzD+vmHtbNPayb61pTM1eWtXCxNBEREbVbDEJERETUbjEIERERUbvFIERERETtFoMQERERtVsMQkRERNRuMQgRERFRu8UgRERERO0WgxARERG1WwxCRERE1G4xCBEREVG7xSBERERE7RYfuupDtXVW/GaswfkauWdCREREAIOQTx0q/RceXL8PXQNVSJd7MkRERMRTY74UrK3PnSaLzBMhIiIiAAxCPqVvCEI1VpknQkRERAAYhHxKr1UBAGotgBBC5tkQERERg5AP6TX1R4QEFLhs5vkxIiIiuTEI+ZBOo4JCUf/3S1woREREJDsGIR9SKBTQaepPj12qrZN5NkRERMQg5GO202M8IkRERCQ/BiEf0/OIEBERkd9gEPIx2yX0PCJEREQkPwYhH7NdQn/JxCNCREREcmMQ8jHbYunqWh4RIiIikhuDkI9Ji6UZhIiIiGTHIORjtjVCVTw1RkREJDsGIR8L5hohIiIivyF7EFqzZg1iYmIQGBiIuLg47N69u9m+e/bswciRI9GpUycEBQUhNjYWK1assOuTl5cHhULh8FNTU+PtTWkVrhEiIiLyHwFyfnl+fj6ysrKwZs0ajBw5Em+++SZSU1Px008/oUePHg799Xo95s6di4EDB0Kv12PPnj147LHHoNfrMXv2bKlfaGgofv75Z7vPBgYGen17WoOXzxMREfkPWYPQ8uXLMXPmTMyaNQsAkJubi23btmHt2rVYtmyZQ/8hQ4ZgyJAh0uuePXvio48+wu7du+2CkEKhQEREhPc3wA2Ni6V5aoyIiEhusgWh2tpaHDx4EPPnz7drT0lJQVFRUavGKC4uRlFREZYuXWrXXlVVhejoaFgsFgwePBgvvPCCXYC6kslkgslkkl4bjUYAgNlshtlsbu0mtUrDEiFU1Xh+7OuZrVasWeuxZu5h3dzDurmHdXNdSzVzp46yBaGKigpYLBaEh4fbtYeHh6O8vLzFz3bv3h3nzp1DXV0dFi1aJB1RAoDY2Fjk5eVhwIABMBqNWLlyJUaOHInDhw+jd+/eTsdbtmwZFi9e7NBeWFgInU7nxtY179gFBQAVys79CwUFBR4duz0wGAxyT6HNYc3cw7q5h3VzD+vmOmc1q66udnkcWU+NAfWnsZoSQji0XWn37t2oqqrCvn37MH/+fPTq1QtTp04FACQkJCAhIUHqO3LkSAwdOhSvv/46Vq1a5XS8nJwcZGdnS6+NRiOioqKQkpKC0NBQdzfNqbBjZ/Gnn0sQEKTH+PG3eXTs65nZbIbBYEBycjLUarXc02kTWDP3sG7uYd3cw7q5rqWa2c7ouEK2INS5c2eoVCqHoz9nz551OEp0pZiYGADAgAED8Ntvv2HRokVSELqSUqnEsGHDcOzYsWbH02q10Gq1Du1qtdrjO2aYrn7R9qVaC3d6N3jjd3K9Y83cw7q5h3VzD+vmOmc1c6eGsl0+r9FoEBcX53Boy2AwICkpqdXjCCHs1vc4e7+kpASRkZFuz9WTePk8ERGR/5D11Fh2djbS09MRHx+PxMRErF+/HqWlpcjIyABQf8rq9OnT2LhxIwBg9erV6NGjB2JjYwHU31fo1Vdfxbx586QxFy9ejISEBPTu3RtGoxGrVq1CSUkJVq9e7fsNdKLpQ1dbcxqQiIiIvEfWIJSWlobz589jyZIlKCsrQ//+/VFQUIDo6GgAQFlZGUpLS6X+VqsVOTk5OH78OAICAnDzzTfjpZdewmOPPSb1uXjxImbPno3y8nKEhYVhyJAh2LVrF4YPH+7z7XPGdh8hqwBqzFYENRwhIiIiIt+TfbF0ZmYmMjMznb6Xl5dn93revHl2R3+cWbFihcPdpv2JTt0YfKpMdQxCREREMpL9ERvtjVKpgEYpAADVvKkiERGRrBiEZBBou6kiH7xKREQkKwYhGdjuLs3njREREcmLQUgGjUGIR4SIiIjkxCAkA21D1fngVSIiInkxCMlAq6pfLM0jQkRERPJiEJJB42JprhEiIiKSE4OQDGxrhKp5RIiIiEhWDEIysAWhKq4RIiIikhWDkAx41RgREZF/YBCSQaC0WJprhIiIiOTEICQDje3yeR4RIiIikhWDkAxsV43xPkJERETyYhCSgZaXzxMREfkFBiEZBHKxNBERkV9gEJKBpmGxNO8jREREJC8GIRk03lmaQYiIiEhODEIyaHzoqgVCCHknQ0RE1I4xCMnAtljaYhUw1VnlnQwREVE7xiAkA1sQArhgmoiISE4MQjJQKoAgdX3peXdpIiIi+TAIyUSvDQDABdNERERyYhCSiU5Tf36smneXJiIikg2DkEz0Gh4RIiIikhuDkEz0DSumuUaIiIhIPgxCMrGtEeJVY0RERPJhEJKJvmGNEJ9AT0REJB8GIZnwiBAREZH8GIRkYjsiVMU1QkRERLJhEJKJ7YgQL58nIiKSD4OQTHTSESEGISIiIrkwCMmEa4SIiIjkxyAkk2AN7yNEREQkNwYhmega7izNy+eJiIjkwyAkk8Y7SzMIERERyYVBSCaNa4R4aoyIiEgusgehNWvWICYmBoGBgYiLi8Pu3bub7btnzx6MHDkSnTp1QlBQEGJjY7FixQqHfps3b0a/fv2g1WrRr18/bNmyxZub4BY9rxojIiKSnaxBKD8/H1lZWViwYAGKi4sxatQopKamorS01Gl/vV6PuXPnYteuXThy5AgWLlyIhQsXYv369VKfvXv3Ii0tDenp6Th8+DDS09MxZcoUfPvtt77arFbhfYSIiIjkJ2sQWr58OWbOnIlZs2ahb9++yM3NRVRUFNauXeu0/5AhQzB16lTceuut6NmzJx555BGMGzfO7ihSbm4ukpOTkZOTg9jYWOTk5GDs2LHIzc310Va1ju2IkNkiYKrj6TEiIiI5BMj1xbW1tTh48CDmz59v156SkoKioqJWjVFcXIyioiIsXbpUatu7dy+efPJJu37jxo1rMQiZTCaYTCbptdFoBACYzWaYzeZWzaW1bOOplVap7WJVDTrqNR79nuuNrW6e/n1cz1gz97Bu7mHd3MO6ua6lmrlTR9mCUEVFBSwWC8LDw+3aw8PDUV5e3uJnu3fvjnPnzqGurg6LFi3CrFmzpPfKy8tdHnPZsmVYvHixQ3thYSF0Ol1rNsdlO778EmqlCmarAp9t245OgV75muuOwWCQewptDmvmHtbNPaybe1g31zmrWXV1tcvjyBaEbBQKhd1rIYRD25V2796Nqqoq7Nu3D/Pnz0evXr0wdepUt8fMyclBdna29NpoNCIqKgopKSkIDQ11ZXOuymw2w2AwIDk5GSHf78GFS2YMTxqFPhEhHv2e603TuqnVarmn0yawZu5h3dzDurmHdXNdSzWzndFxhWxBqHPnzlCpVA5Has6ePetwROdKMTExAIABAwbgt99+w6JFi6QgFBER4fKYWq0WWq3WoV2tVnttx1Sr1QjWqnHhkhkmK/gfQCt583dyvWLN3MO6uYd1cw/r5jpnNXOnhrItltZoNIiLi3M4tGUwGJCUlNTqcYQQdut7EhMTHcYsLCx0aUxfsV05VsV7CREREclC1lNj2dnZSE9PR3x8PBITE7F+/XqUlpYiIyMDQP0pq9OnT2Pjxo0AgNWrV6NHjx6IjY0FUH9foVdffRXz5s2TxnziiSdw++234+WXX8aECROwdetWbN++HXv27PH9Bl6F7cqxat5LiIiISBayBqG0tDScP38eS5YsQVlZGfr374+CggJER0cDAMrKyuzuKWS1WpGTk4Pjx48jICAAN998M1566SU89thjUp+kpCRs2rQJCxcuxLPPPoubb74Z+fn5GDFihM+372oajwgxCBEREclB9sXSmZmZyMzMdPpeXl6e3et58+bZHf1pzuTJkzF58mRPTM+rgqXHbDAIERERyUH2R2y0Z9KDV2u5RoiIiEgODEIy0ml4RIiIiEhODEIy4qkxIiIieTEIyYiXzxMREcmLQUhGwQ1rhPgEeiIiInkwCMnItkaIl88TERHJg0FIRnquESIiIpIVg5CMGhdLc40QERGRHBiEZNR4HyEeESIiIpIDg5CMeGqMiIhIXgxCMtLz1BgREZGsGIRkFNxw1VitxYraOqvMsyEiImp/GIRkpGtYIwTwXkJERERyYBCSkVqlhCag/lfAewkRERH5HoOQzHgJPRERkXwYhGRmu4SeR4SIiIh8j0FIZvqGBdNcI0REROR7DEIy472EiIiI5MMgJDNbEKriGiEiIiKfYxCSWXDDGiGeGiMiIvI9BiGZ6TS2I0IMQkRERL7GICSzYK4RIiIikg2DkMykJ9BzjRAREZHPMQjJzHZqjEeEiIiIfI9BSGbSqTEuliYiIvI5BiGZ8fJ5IiIi+TAIySxYWiPEI0JERES+xiAkM64RIiIikg+DkMz0XCNEREQkGwYhmTXeR4hrhIiIiHyNQUhmeq4RIiIikg2DkMz0DWuETHVW1FmsMs+GiIiofWEQkpltjRDA02NERES+xiAkM02AEhpV/a+higumiYiIfIpByA/Y1glVc50QERGRTzEI+QHbvYSqGISIiIh8SvYgtGbNGsTExCAwMBBxcXHYvXt3s30/+ugjJCcno0uXLggNDUViYiK2bdtm1ycvLw8KhcLhp6amxtub4jZeQk9ERCQPWYNQfn4+srKysGDBAhQXF2PUqFFITU1FaWmp0/67du1CcnIyCgoKcPDgQYwZMwb33nsviouL7fqFhoairKzM7icwMNAXm+QW26kxHhEiIiLyrYCrd/Ge5cuXY+bMmZg1axYAIDc3F9u2bcPatWuxbNkyh/65ubl2r1988UVs3boVn376KYYMGSK1KxQKREREeHXunmS7cqyai6WJiIh8SrYgVFtbi4MHD2L+/Pl27SkpKSgqKmrVGFarFZWVlejYsaNde1VVFaKjo2GxWDB48GC88MILdkHpSiaTCSaTSXptNBoBAGazGWazubWb1Cq28ZqOG6SuPzBnrDZ5/PuuF87qRi1jzdzDurmHdXMP6+a6lmrmTh1lC0IVFRWwWCwIDw+3aw8PD0d5eXmrxnjttddw6dIlTJkyRWqLjY1FXl4eBgwYAKPRiJUrV2LkyJE4fPgwevfu7XScZcuWYfHixQ7thYWF0Ol0LmxV6xkMBunvF88pAShx8Pu/o8P5H73yfdeLpnWj1mHN3MO6uYd1cw/r5jpnNauurnZ5HFlPjQH1p7GaEkI4tDnzwQcfYNGiRdi6dSu6du0qtSckJCAhIUF6PXLkSAwdOhSvv/46Vq1a5XSsnJwcZGdnS6+NRiOioqKQkpKC0NBQVzepRWazGQaDAcnJyVCr1QCAA/97BN+dO4WomN4Y/7teHv2+64WzulHLWDP3sG7uYd3cw7q5rqWa2c7ouEK2INS5c2eoVCqHoz9nz551OEp0pfz8fMycORMffvghfve737XYV6lUYtiwYTh27FizfbRaLbRarUO7Wq322o7ZdOzgIA0A4HKdlf8hXIU3fyfXK9bMPaybe1g397BurnNWM3dqKNtVYxqNBnFxcQ6HtgwGA5KSkpr93AcffIAZM2bg/fffx913333V7xFCoKSkBJGRkdc8Z29pvHyei6WJiIh8SdZTY9nZ2UhPT0d8fDwSExOxfv16lJaWIiMjA0D9KavTp09j48aNAOpD0LRp07By5UokJCRIR5OCgoIQFhYGAFi8eDESEhLQu3dvGI1GrFq1CiUlJVi9erU8G9kKeo3tCfS8jxAREZEvyRqE0tLScP78eSxZsgRlZWXo378/CgoKEB0dDQAoKyuzu6fQm2++ibq6OsyZMwdz5syR2qdPn468vDwAwMWLFzF79myUl5cjLCwMQ4YMwa5duzB8+HCfbpsrbJfPX+Ll80RERD4l+2LpzMxMZGZmOn3PFm5sdu7cedXxVqxYgRUrVnhgZr6j56kxIiIiWcj+iA1qDEJVPDVGRETkUwxCfiBYa1sjxCNCREREvsQg5AdsT5/nIzaIiIh8i0HIDwRLp8YYhIiIiHyJQcgP2NYI1ZitqLNYZZ4NERFR+8Eg5Af0DWuEAKDazAXTREREvsIg5Ac0KiUClPXPV+OCaSIiIt9hEPIDCoWC9xIiIiKSAYOQnwjmvYSIiIh8jkHIT9jWCVXziBAREZHPMAj5Cdu9hHgJPRERke8wCPmJYD54lYiIyOcYhPyE7dQY1wgRERH5DoOQn7BdNcY1QkRERL7DIOQn9BpePk9ERORrDEJ+Qs/L54mIiHyOQchPBDesEeIRISIiIt9hEPITtsvnedUYERGR7zAI+YlgPmKDiIjI5xiE/ETjs8a4RoiIiMhXGIT8hO0+Qjw1RkRE5DsMQn6CT58nIiLyPQYhP6HX8PJ5IiIiX2MQ8hNcLE1EROR7DEJ+wrZG6LLZAotVyDwbIiKi9oFByE/Y1ggBQDUXTBMREfkEg5Cf0AYooVIqAPASeiIiIl9hEPITCoUCek396bEqrhMiIiLyCQYhP2I7PcZTY0RERL7BIORHGp9AzyBERETkCwxCfoSP2SAiIvItBiE/EtxwCT1PjREREfkGg5Af0Wl4aoyIiMiXGIT8CO8uTURE5FsMQn7EdndpPm+MiIjINxiE/Ih0+TyPCBEREfmE7EFozZo1iImJQWBgIOLi4rB79+5m+3700UdITk5Gly5dEBoaisTERGzbts2h3+bNm9GvXz9otVr069cPW7Zs8eYmeIztCfSXuFiaiIjIJ9wKQqdOncKvv/4qvf7uu++QlZWF9evXuzROfn4+srKysGDBAhQXF2PUqFFITU1FaWmp0/67du1CcnIyCgoKcPDgQYwZMwb33nsviouLpT579+5FWloa0tPTcfjwYaSnp2PKlCn49ttv3dlUn2q8jxBPjREREfmCW0HooYcewo4dOwAA5eXlSE5OxnfffYdnnnkGS5YsafU4y5cvx8yZMzFr1iz07dsXubm5iIqKwtq1a532z83NxR/+8AcMGzYMvXv3xosvvojevXvj008/teuTnJyMnJwcxMbGIicnB2PHjkVubq47m+pTtsvnuViaiIjINwKu3sXRjz/+iOHDhwMA/vrXv6J///745ptvUFhYiIyMDDz33HNXHaO2thYHDx7E/Pnz7dpTUlJQVFTUqnlYrVZUVlaiY8eOUtvevXvx5JNP2vUbN25ci0HIZDLBZDJJr41GIwDAbDbDbDa3ai6tZRvP2bhaVf1DV6tqPP+9bV1LdSPnWDP3sG7uYd3cw7q5rqWauVNHt4KQ2WyGVqsFAGzfvh333XcfACA2NhZlZWWtGqOiogIWiwXh4eF27eHh4SgvL2/VGK+99houXbqEKVOmSG3l5eUuj7ls2TIsXrzYob2wsBA6na5Vc3GVwWBwaPvpXwoAKpw5dwEFBQVe+d62zlndqGWsmXtYN/ewbu5h3VznrGbV1dUuj+NWELr11luxbt063H333TAYDHjhhRcAAGfOnEGnTp1cGkuhUNi9FkI4tDnzwQcfYNGiRdi6dSu6du16TWPm5OQgOztbem00GhEVFYWUlBSEhoa2ZjNazWw2w2AwIDk5GWq12u69Lif+hfVH9yMgUI/x42/z6Pe2dS3VjZxjzdzDurmHdXMP6+a6lmpmO6PjCreC0Msvv4yJEyfif/7nfzB9+nQMGjQIAPDJJ59Ip8yupnPnzlCpVA5Has6ePetwROdK+fn5mDlzJj788EP87ne/s3svIiLC5TG1Wq10hKsptVrttR3T2dhh+vo5VNda+B9EM7z5O7lesWbuYd3cw7q5h3VznbOauVNDtxZL33HHHaioqEBFRQXeeecdqX327NlYt25dq8bQaDSIi4tzOLRlMBiQlJTU7Oc++OADzJgxA++//z7uvvtuh/cTExMdxiwsLGxxTH8hXT7PxdJEREQ+4dYRocuXL0MIgQ4dOgAATp48iS1btqBv374YN25cq8fJzs5Geno64uPjkZiYiPXr16O0tBQZGRkA6k9ZnT59Ghs3bgRQH4KmTZuGlStXIiEhQTryExQUhLCwMADAE088gdtvvx0vv/wyJkyYgK1bt2L79u3Ys2ePO5vqU9LT52stsFoFlMqrnyIkIiIi97l1RGjChAlSOLl48SJGjBiB1157Dffff3+zl747k5aWhtzcXCxZsgSDBw/Grl27UFBQgOjoaABAWVmZ3T2F3nzzTdTV1WHOnDmIjIyUfp544gmpT1JSEjZt2oQNGzZg4MCByMvLQ35+PkaMGOHOpvqU7VljAFBt5r2EiIiIvM2tI0KHDh3CihUrAAB/+9vfEB4ejuLiYmzevBnPPfccHn/88VaPlZmZiczMTKfv5eXl2b3euXNnq8acPHkyJk+e3Oo5+ItAtRJKBWAV9Y/ZaBqMiIiIyPPcOiJUXV2NkJAQAPXrbyZNmgSlUomEhAScPHnSoxNsTxQKhbROqIrrhIiIiLzOrSDUq1cvfPzxxzh16hS2bduGlJQUAPVXZ3n6cvP2RlonxMdsEBEReZ1bQei5557D008/jZ49e2L48OFITEwEUH90aMiQIR6dYHujb3jMBo8IEREReZ9bi1AmT56M2267DWVlZdI9hABg7NixmDhxoscm1x7Z1gVV8wn0REREXuf2atyIiAhERETg119/hUKhwI033tjqmylS83RcI0REROQzbp0as1qtWLJkCcLCwhAdHY0ePXrghhtuwAsvvACr1erpObYrXCNERETkO24dEVqwYAHefvttvPTSSxg5ciSEEPjmm2+waNEi1NTU4I9//KOn59luBDesEeKpMSIiIu9zKwi9++67eOutt6SnzgPAoEGDcOONNyIzM5NB6BrotDw1RkRE5CtunRq7cOECYmNjHdpjY2Nx4cKFa55Uexas5fPGiIiIfMWtIDRo0CC88cYbDu1vvPEGBg4ceM2Tas8ab6jINUJERETe5tapsVdeeQV33303tm/fjsTERCgUChQVFeHUqVMoKCjw9BzbFT3XCBEREfmMW0eERo8ejX/84x+YOHEiLl68iAsXLmDSpEn4+9//jg0bNnh6ju2KnqfGiIiIfMbt+wh169bNYVH04cOH8e677+Kdd9655om1V3ouliYiIvIZt44IkffYLp/nfYSIiIi8j0HIz9gWS1/iGiEiIiKvYxDyM1wjRERE5DsurRGaNGlSi+9fvHjxWuZC4CM2iIiIfMmlIBQWFnbV96dNm3ZNE2rvbJfPX6qtgxACCoVC5hkRERFdv1wKQrw03vtsa4SEAC6bLdLT6ImIiMjzuEbIz+g0KtgOAvESeiIiIu9iEPIzCoWi8coxrhMiIiLyKgYhPyStE+IRISIiIq9iEPJDjUeEGISIiIi8iUHID0mX0POmikRERF7FIOSHbKfGqrhGiIiIyKsYhPxQcMMRoWqeGiMiIvIqBiE/ZLt3EC+fJyIi8i4GIT/Ex2wQERH5BoOQHwpu8pgNIiIi8h4GIT/EJ9ATERH5BoOQH+J9hIiIiHyDQcgP2Y4I8fJ5IiIi72IQ8kO2+whVc40QERGRVzEI+SGeGiMiIvINBiE/1HhqjEGIiIjImxiE/FAw7yNERETkE7IHoTVr1iAmJgaBgYGIi4vD7t27m+1bVlaGhx56CH369IFSqURWVpZDn7y8PCgUCoefmpoaL26FZ+l5HyEiIiKfkDUI5efnIysrCwsWLEBxcTFGjRqF1NRUlJaWOu1vMpnQpUsXLFiwAIMGDWp23NDQUJSVldn9BAYGemszPK7pfYSEEDLPhoiI6PolaxBavnw5Zs6ciVmzZqFv377Izc1FVFQU1q5d67R/z549sXLlSkybNg1hYWHNjqtQKBAREWH305bYgpBVADVmq8yzISIiun4FyPXFtbW1OHjwIObPn2/XnpKSgqKiomsau6qqCtHR0bBYLBg8eDBeeOEFDBkypNn+JpMJJpNJem00GgEAZrMZZrP5muZyJdt4LY2rRuNRoIuXLiNAofXoHNqi1tSN7LFm7mHd3MO6uYd1c11LNXOnjrIFoYqKClgsFoSHh9u1h4eHo7y83O1xY2NjkZeXhwEDBsBoNGLlypUYOXIkDh8+jN69ezv9zLJly7B48WKH9sLCQuh0Orfn0hKDwdDi+1qlCiarAgWFX6Jz2zmr53VXqxs5Ys3cw7q5h3VzD+vmOmc1q66udnkc2YKQjUKhsHsthHBoc0VCQgISEhKk1yNHjsTQoUPx+uuvY9WqVU4/k5OTg+zsbOm10WhEVFQUUlJSEBoa6vZcnDGbzTAYDEhOToZarW6239IfduJcVS3iE29Dv0jPzqEtam3dqBFr5h7WzT2sm3tYN9e1VDPbGR1XyBaEOnfuDJVK5XD05+zZsw5Hia6FUqnEsGHDcOzYsWb7aLVaaLWOp5/UarXXdsyrjR0cqMa5qlqYLAr+x9GEN38n1yvWzD2sm3tYN/ewbq5zVjN3aijbYmmNRoO4uDiHQ1sGgwFJSUke+x4hBEpKShAZGemxMX2Bl9ATERF5n6ynxrKzs5Geno74+HgkJiZi/fr1KC0tRUZGBoD6U1anT5/Gxo0bpc+UlJQAqF8Qfe7cOZSUlECj0aBfv34AgMWLFyMhIQG9e/eG0WjEqlWrUFJSgtWrV/t8+66Fjo/ZICIi8jpZg1BaWhrOnz+PJUuWoKysDP3790dBQQGio6MB1N9A8cp7CjW9+uvgwYN4//33ER0djRMnTgAALl68iNmzZ6O8vBxhYWEYMmQIdu3aheHDh/tsuzwhWMsgRERE5G2yL5bOzMxEZmam0/fy8vIc2q52g8EVK1ZgxYoVnpiarBqfN8bHbBAREXmL7I/YIOeCG9YIVfOIEBERkdcwCPkp2xqhKi6WJiIi8hoGIT+l5xohIiIir2MQ8lO2U2OXuEaIiIjIaxiE/BSPCBEREXkfg5Cf0tvuI8Q1QkRERF7DIOSnePk8ERGR9zEI+Sk9L58nIiLyOgYhP8U7SxMREXkfg5Cfku4jxCBERETkNQxCfko6IlRruepjRYiIiMg9DEJ+yrZGyGIVMNVZZZ4NERHR9YlByE/ZTo0BXCdERETkLQxCfkqlVCBIzbtLExEReRODkB9rvJcQjwgRERF5A4OQH7M9b6yad5cmIiLyCgYhP8ZL6ImIiLyLQciPNd5UkWuEiIiIvIFByI/ZLqHng1eJiIi8g0HIj+n5mA0iIiKvYhDyY3oNgxAREZE3MQj5scbL57lGiIiIyBsYhPwYL58nIiLyLgYhP6bjDRWJiIi8ikHIj3GxNBERkXcxCPkx26kx3keIiIjIOxiE/Jh01RjXCBEREXkFg5Af46kxIiIi72IQ8mN6PmKDiIjIqxiE/JhtjRCvGiMiIvIOBiE/ZjsixPsIEREReQeDkB/TNSyWNlsETHU8PUZERORpDEJ+TK9RSX/nOiEiIiLPYxDyYwEqJQLV9b8iXjlGRETkeQxCfi5Yy3sJEREReYvsQWjNmjWIiYlBYGAg4uLisHv37mb7lpWV4aGHHkKfPn2gVCqRlZXltN/mzZvRr18/aLVa9OvXD1u2bPHS7L3Ptk6IR4SIiIg8T9YglJ+fj6ysLCxYsADFxcUYNWoUUlNTUVpa6rS/yWRCly5dsGDBAgwaNMhpn7179yItLQ3p6ek4fPgw0tPTMWXKFHz77bfe3BSv0UsPXuUaISIiIk+TNQgtX74cM2fOxKxZs9C3b1/k5uYiKioKa9euddq/Z8+eWLlyJaZNm4awsDCnfXJzc5GcnIycnBzExsYiJycHY8eORW5urhe3xHts9xKq5hEhIiIij5MtCNXW1uLgwYNISUmxa09JSUFRUZHb4+7du9dhzHHjxl3TmHKynRrjTRWJiIg8L0CuL66oqIDFYkF4eLhde3h4OMrLy90et7y83OUxTSYTTCaT9NpoNAIAzGYzzGaz23NxxjZea8fVNVw1Zrxc6/G5tCWu1o1YM3exbu5h3dzDurmupZq5U0fZgpCNQqGwey2EcGjz9pjLli3D4sWLHdoLCwuh0+muaS7NMRgMrep34awSgBKHvv87Ol/40StzaUtaWzdqxJq5h3VzD+vmHtbNdc5qVl1d7fI4sgWhzp07Q6VSORypOXv2rMMRHVdERES4PGZOTg6ys7Ol10ajEVFRUUhJSUFoaKjbc3HGbDbDYDAgOTkZarX6qv0PFRzFt+dKERXTC+OTe3t0Lm2Jq3Uj1sxdrJt7WDf3sG6ua6lmtjM6rpAtCGk0GsTFxcFgMGDixIlSu8FgwIQJE9weNzExEQaDAU8++aTUVlhYiKSkpGY/o9VqodVqHdrVarXXdszWjh0SqAEAXDZb+R8JvPs7uV6xZu5h3dzDurmHdXOds5q5U0NZT41lZ2cjPT0d8fHxSExMxPr161FaWoqMjAwA9UdqTp8+jY0bN0qfKSkpAQBUVVXh3LlzKCkpgUajQb9+/QAATzzxBG6//Xa8/PLLmDBhArZu3Yrt27djz549Pt8+T+Dl80RERN4jaxBKS0vD+fPnsWTJEpSVlaF///4oKChAdHQ0gPobKF55T6EhQ4ZIfz948CDef/99REdH48SJEwCApKQkbNq0CQsXLsSzzz6Lm2++Gfn5+RgxYoTPtsuTpMvneWdpIiIij5N9sXRmZiYyMzOdvpeXl+fQJoS46piTJ0/G5MmTr3VqfqHxiBCDEBERkafJ/ogNahkfsUFEROQ9DEJ+TnroKtcIEREReRyDkJ/TN6wR4tPniYiIPI9ByM/ptTw1RkRE5C0MQn5Oz1NjREREXsMg5OeCGxZL11qsqK2zyjwbIiKi6wuDkJ/TNawRAngvISIiIk9jEPJzapUSmoD6XxPvJURERORZDEJtAC+hJyIi8g4GoTaAl9ATERF5B4NQG6Dn3aWJiIi8gkGoDeC9hIiIiLyDQagNaHzwKtcIEREReRKDUBsQ3LBGiJfPExEReRaDUBtgWyPEy+eJiIg8i0GoDeAaISIiIu9gEGoDpMvnuUaIiIjIoxiE2gAeESIiIvIOBqE2QLqPEBdLExEReRSDUBvAy+eJiIi8g0GoDZAun+epMSIiIo9iEGoDGo8IMQgRERF5EoNQG6DjGiEiIiKvYBBqA4Klq8a4RoiIiMiTGITagMb7CPGIEBERkScxCLUBtiNCpjor6ixWmWdDRER0/WAQagNsa4QAnh4jIiLyJAahNkAToIRGVf+rquKCaSIiIo9hEGoj9LyXEBERkccxCLURttNjvJcQERGR5zAItRG8hJ6IiMjzGITaCNupMR4RIiIi8hwGoTbC9piNai6WJiIi8hgGoTZCb3vMBo8IEREReQyDUBvR+OBVrhEiIiLyFAahNiLYdvk8T40RERF5jOxBaM2aNYiJiUFgYCDi4uKwe/fuFvt//fXXiIuLQ2BgIG666SasW7fO7v28vDwoFAqHn5qaGm9uhtc1HhFiECIiIvIUWYNQfn4+srKysGDBAhQXF2PUqFFITU1FaWmp0/7Hjx/H+PHjMWrUKBQXF+OZZ57Bf/3Xf2Hz5s12/UJDQ1FWVmb3ExgY6ItN8hq9lmuEiIiIPC3g6l28Z/ny5Zg5cyZmzZoFAMjNzcW2bduwdu1aLFu2zKH/unXr0KNHD+Tm5gIA+vbtiwMHDuDVV1/FAw88IPVTKBSIiIjwyTb4il5jewI91wgRERF5imxHhGpra3Hw4EGkpKTYtaekpKCoqMjpZ/bu3evQf9y4cThw4ADMZrPUVlVVhejoaHTv3h333HMPiouLPb8BPiYdEeIaISIiIo+R7YhQRUUFLBYLwsPD7drDw8NRXl7u9DPl5eVO+9fV1aGiogKRkZGIjY1FXl4eBgwYAKPRiJUrV2LkyJE4fPgwevfu7XRck8kEk8kkvTYajQAAs9lsF7A8wTaeq+M2rJVGVY3n59QWuFu39ow1cw/r5h7WzT2sm+taqpk7dZT11BhQfxqrKSGEQ9vV+jdtT0hIQEJCgvT+yJEjMXToULz++utYtWqV0zGXLVuGxYsXO7QXFhZCp9O1bkNcZDAYXOp/5KICgApl5/6FgoICr8ypLXC1bsSauYt1cw/r5h7WzXXOalZdXe3yOLIFoc6dO0OlUjkc/Tl79qzDUR+biIgIp/0DAgLQqVMnp59RKpUYNmwYjh071uxccnJykJ2dLb02Go2IiopCSkoKQkNDW7tJrWI2m2EwGJCcnAy1Wt3qz0WUXsS6I99BqdVh/PhRHp1TW+Bu3doz1sw9rJt7WDf3sG6ua6lmtjM6rpAtCGk0GsTFxcFgMGDixIlSu8FgwIQJE5x+JjExEZ9++qldW2FhIeLj45vdgYQQKCkpwYABA5qdi1arhVardWhXq9Ve2zFdHTtMXz+/y2ZLu/6PxZu/k+sVa+Ye1s09rJt7WDfXOauZOzWU9fL57OxsvPXWW3jnnXdw5MgRPPnkkygtLUVGRgaA+iM106ZNk/pnZGTg5MmTyM7OxpEjR/DOO+/g7bffxtNPPy31Wbx4MbZt24ZffvkFJSUlmDlzJkpKSqQx2yrbIzZ4HyEiIiLPkXWNUFpaGs6fP48lS5agrKwM/fv3R0FBAaKjowEAZWVldvcUiomJQUFBAZ588kmsXr0a3bp1w6pVq+wunb948SJmz56N8vJyhIWFYciQIdi1axeGDx/u8+3zJNtVYzVmK+osVgSoZL8XJhERUZsn+2LpzMxMZGZmOn0vLy/PoW306NE4dOhQs+OtWLECK1as8NT0/IbedtkYgGqzBaEMQkRERNeM/5q2EdoAFdSq+ivjeHdpIiIiz2AQakN0Gj5mg4iIyJMYhNqQYOnBq3zMBhERkScwCLUhtnVC1TwiRERE5BEMQm2IXstL6ImIiDyJQagNsd1LiA9eJSIi8gwGoTbkBl39HTM/+O4UjDV8QB8REdG1YhBqQ2aNugnB2gB8d/wCpqzbi9+MNXJPiYiIqE1jEGpDBkfdgE2zE9A5WIuj5ZWYtKYI/3euSu5pERERtVkMQm1M/xvDsCUzCTGd9Th98TImry3CodJ/yT0tIiKiNolBqA2K6qjD3zISMah7GP5VbcZDf9qHL4/8Jve0iIiI2hwGoTaqU7AWH8xOwB19uqDGbMXsPx/EX/efkntaREREbQqDUBum0wTgT9PiMTmuOyxWgT9s/h6vf3kMQgi5p0ZERNQmMAi1cWqVEv8zeSDmjLkZAPCa4R94duuPsFgZhoiIiK6GQeg6oFAo8P/GxWLxfbdCoQD+sq8Uc947hBozn0lGRETUEgah68j0pJ54Y+pQaFRKfPH3ckx7+zv8u5o3XiQiImoOg9B15u6BkXj30eEI0QbguxMX8B9vFqHs35flnhYREZFfYhC6DiXe3Al/zUhE1xAt/vFbFSatKcKx3yrlnhYREZHfYRC6TvWNDMVHmUm4qYseZf+uweR1e3HgxAW5p0VERORXGISuY9076LA5IwlDetyAf1824+G3vkXeN8fx0xkjauusck+PiIhIdgFyT4C8q4Neg/dnJWDu+4fw5dGzWPTpTwAAtUqBm7sEo1+3UPSLDEXfhp+Oeo3MMyYiIvIdBqF2IEijwpvpcXhz1y/Y9Y9z+KnMiMqaOhwtr8TR8kp8hNNS34jQQPTrFoq+kSHoFxmGvpEh6NlJD6VSIeMWEBEReQeDUDsRoFJizphemDOmF4QQOH3xMn46Y8SRskocKTPipzIjSi9Uo9xYg3JjDb46elb6bJBahdjIEMRGhCAiNAidQzToHKxF52AtugRr0SVEiyCNSsatIyIicg+DUDukUCjQvYMO3TvokHJrhNReWWPG0fL6YHSkzIifzhhxtLwSl80WFJdeRHHpxWbH1GtU6ByibQhIGnSR/t4QmEI06KDTIDRIjZDAAGgDGJyIiEh+DEIkCQlUY1jPjhjWs6PUVmex4sT5S/iprBL//K0S56pMOFdZi4oqE85VmlBRZYKpzopLtRZcOl+Nk+erW/VdmgAlQgPVCA0MQEhggBSQQrRqhAYFICSw/nVow586tQInq4BjZ6sQElR/BEqnUSEwQMXTdkRE5DYGIWpRgEqJXl1D0KtriNP3hRCoMtWhoso+HFVUmnDuirZ/V5tRaaoDANTWWev7VZlcmQ2W/1Dk0KoNUEKnUSFIrUJgw586jQqBavu/awKU0KiU9X/aflRKaNUqaFX2bba/a5v+qVJBq258XxugRICKF14SEbVlDEJ0TRQKRcPRGzViOuuv2t9irQ9OxstmVNbUobLGDGPDn5U1De2mhvbLdTA2ab9grIIiQIPLZgtqzI2X/5vqrDDVWfEv+P5xIkoFGkKRqkmwavizoV0doECAUokApQIqpQIBKgVUTV/b/alseL+xXa1SSq/Vqvr31U36qVVKu/dsbbBacKoK+KnMCK1GDZVCAaVSAZWivo/t70olHNpUSgWU0p/1v2ciousRgxD5lEqpQFiQGmFBapc+ZzabUVBQgPHjx0CtVsNqFaips+ByrQWXzfZ/VpstqLG9bmirMVtQW2eFyWJFbV39j6mu8e+1TdstVpjMFru2WosVJnP9nxarkOZlFUCN2WoXzPxLAF79Yd81j6JQwC5IKRWo/7sUpurbpD4NQUqpQMOfivoxmrQrmr6vdN7XNl5Ak5AWYBfiGgOjUlEfMusDXP1YiobJKxWAArbvrf9uxRVtyoawZ7VacbRMgfP7SqEOUDXMs3F+CmnOttdN5w77/spmPtuK9+v/3jBX2Lcrruhvvy2N26tQAgpc0WarwZX9GXapnWIQojZJqVRApwmATuP7XbjOckVwahqqrghRtnaLVcBiFaizClis1oY/ReOfFuftZosVdRYBs9Uq9TNb6vvZ3quzWmFu+LP+tUCdxQqzxYqqS5eh0WphFYBF1I9ptQpYhIDV2th2NUIAdULUJ792QYWPThyVexI+p3AIdFcGM/ujhHbvQ+DyZRVe+3n3FaHtyhBmHz7tgtoVfR3CnvS+szaFtA22oNfwfw3ttu9qDIdAw/tXBmXUB12gSSC1zd82lpMgrVA09pdeo7GmtvWMTcOv1WrBkTMK/FZ0sj54241fP2G77YX99imbbJetD3BF7aS6XFlvJ7+XFsNyfU2c/a6a1k3RpG6NNbTfDgDQqpXoGhLolX3ZFQxCRC4KUNWvDdL5+b0nG4+i3QG1uuUjcKIhEF0ZkKxWAauwb5fapD9xxWsBq6hvszb8XdjGaGgXTcYTTdqlvlb78S0NQdAiAGtDULQ26dc498YQCdi+q+HPhu2UXjfkOoH6v4uGPnUWK86cOYOIiEhAobCb15XztDZsR9PxLVbn/W11azonq6g/XWzf137OVmvD/GD/vl2fhrZrJWyBuf6VGyMocN7Ehzy7ToWPT/4s9yR8bkiPG7Alc6Tc02AQIqL6/+8uQKXg/yDAFiB/xfjxg64aIP2N1doYyOxDXv3fmwY0XBEQrU3CYNPwJpoENMeA1/i+qdaMoqIiJCYmQalSSSHuynk0DW/SHIQtFANA08Dc+KeAY+i0isbwBgCQ3rO9bHxti3Wi4U2pD+yDZtPP2sa31a7p+Fduh7Ptta9RY3hu+rrOYsXpM6cRGdkNUCjQUAK7MWzzaxrYG39X9ttkV6/mfs8Nne3n2jhO0++0+z1d+R129W1SL2f7lbQNjd+rDfCPi034v3tERNeJxltJ+H69j9lsxpmQ+v8vv60FSDnVB+9TGD9+IOsmE/+IY0REREQyYBAiIiKidotBiIiIiNotBiEiIiJqt2QPQmvWrEFMTAwCAwMRFxeH3bt3t9j/66+/RlxcHAIDA3HTTTdh3bp1Dn02b96Mfv36QavVol+/ftiyZYu3pk9ERERtmKxBKD8/H1lZWViwYAGKi4sxatQopKamorS01Gn/48ePY/z48Rg1ahSKi4vxzDPP4L/+67+wefNmqc/evXuRlpaG9PR0HD58GOnp6ZgyZQq+/fZbX20WERERtRGyBqHly5dj5syZmDVrFvr27Yvc3FxERUVh7dq1TvuvW7cOPXr0QG5uLvr27YtZs2bh0Ucfxauvvir1yc3NRXJyMnJychAbG4ucnByMHTsWubm5PtoqIiIiaitkC0K1tbU4ePAgUlJS7NpTUlJQVOT4hHGg/mjPlf3HjRuHAwcOwGw2t9inuTGJiIio/ZLthooVFRWwWCwIDw+3aw8PD0d5ebnTz5SXlzvtX1dXh4qKCkRGRjbbp7kxAcBkMsFkMkmvjUYjgPobXdkClqfYxvP0uNc71s11rJl7WDf3sG7uYd1c11LN3Kmj7HeWvvKJx0KIFp+C7Kz/le2ujrls2TIsXrzYob2wsBA6na75yV8Dg8HglXGvd6yb61gz97Bu7mHd3MO6uc5Zzaqrq10eR7Yg1LlzZ6hUKocjNWfPnnU4omMTERHhtH9AQAA6derUYp/mxgSAnJwcZGdnS6+NRiOioqKQkpKC0NBQl7brasxmMwwGA5KTk3k7dRewbq5jzdzDurmHdXMP6+a6lmpmO6PjCtmCkEajQVxcHAwGAyZOnCi1GwwGTJgwwelnEhMT8emnn9q1FRYWIj4+XipGYmIiDAYDnnzySbs+SUlJzc5Fq9VCq9U6tKvVaq/tmN4c+3rGurmONXMP6+Ye1s09rJvrnNXMnRrKemosOzsb6enpiI+PR2JiItavX4/S0lJkZGQAqD9Sc/r0aWzcuBEAkJGRgTfeeAPZ2dn4/e9/j7179+Ltt9/GBx98II35xBNP4Pbbb8fLL7+MCRMmYOvWrdi+fTv27NkjyzYSERGR/5I1CKWlpeH8+fNYsmQJysrK0L9/fxQUFCA6OhoAUFZWZndPoZiYGBQUFODJJ5/E6tWr0a1bN6xatQoPPPCA1CcpKQmbNm3CwoUL8eyzz+Lmm29Gfn4+RowY4fPtIyIiIv8m+2LpzMxMZGZmOn0vLy/PoW306NE4dOhQi2NOnjwZkydPdntOtgXY7pxrvBqz2Yzq6moYjUYeBnUB6+Y61sw9rJt7WDf3sG6ua6lmtn+3bf+Ot4bsQcgfVVZWAgCioqJkngkRERG5qrKyEmFhYa3qqxCuxKZ2wmq14syZMwgJCWnxsnt32K5IO3XqlMevSLuesW6uY83cw7q5h3VzD+vmupZqJoRAZWUlunXrBqWydfeM5hEhJ5RKJbp37+7V7wgNDeVO7wbWzXWsmXtYN/ewbu5h3VzXXM1aeyTIRvanzxMRERHJhUGIiIiI2i0GIR/TarV4/vnnnd7AkZrHurmONXMP6+Ye1s09rJvrPF0zLpYmIiKidotHhIiIiKjdYhAiIiKidotBiIiIiNotBiEiIiJqtxiEfGjNmjWIiYlBYGAg4uLisHv3brmn5NcWLVoEhUJh9xMRESH3tPzOrl27cO+996Jbt25QKBT4+OOP7d4XQmDRokXo1q0bgoKCcMcdd+Dvf/+7PJP1I1er24wZMxz2v4SEBHkm6yeWLVuGYcOGISQkBF27dsX999+Pn3/+2a4P9zdHrakb9zd7a9euxcCBA6WbJiYmJuLzzz+X3vfkfsYg5CP5+fnIysrCggULUFxcjFGjRiE1NRWlpaVyT82v3XrrrSgrK5N+fvjhB7mn5HcuXbqEQYMG4Y033nD6/iuvvILly5fjjTfewP79+xEREYHk5GTpmXrt1dXqBgB33XWX3f5XUFDgwxn6n6+//hpz5szBvn37YDAYUFdXh5SUFFy6dEnqw/3NUWvqBnB/a6p79+546aWXcODAARw4cAB33nknJkyYIIUdj+5ngnxi+PDhIiMjw64tNjZWzJ8/X6YZ+b/nn39eDBo0SO5ptCkAxJYtW6TXVqtVREREiJdeeklqq6mpEWFhYWLdunUyzNA/XVk3IYSYPn26mDBhgizzaSvOnj0rAIivv/5aCMH9rbWurJsQ3N9ao0OHDuKtt97y+H7GI0I+UFtbi4MHDyIlJcWuPSUlBUVFRTLNqm04duwYunXrhpiYGDz44IP45Zdf5J5Sm3L8+HGUl5fb7XtarRajR4/mvtcKO3fuRNeuXXHLLbfg97//Pc6ePSv3lPzKv//9bwBAx44dAXB/a60r62bD/c05i8WCTZs24dKlS0hMTPT4fsYg5AMVFRWwWCwIDw+3aw8PD0d5eblMs/J/I0aMwMaNG7Ft2zb86U9/Qnl5OZKSknD+/Hm5p9Zm2PYv7nuuS01NxXvvvYevvvoKr732Gvbv348777wTJpNJ7qn5BSEEsrOzcdttt6F///4AuL+1hrO6AdzfnPnhhx8QHBwMrVaLjIwMbNmyBf369fP4fsanz/uQQqGwey2EcGijRqmpqdLfBwwYgMTERNx888149913kZ2dLePM2h7ue65LS0uT/t6/f3/Ex8cjOjoan332GSZNmiTjzPzD3Llz8f3332PPnj0O73F/a15zdeP+5qhPnz4oKSnBxYsXsXnzZkyfPh1ff/219L6n9jMeEfKBzp07Q6VSOSTVs2fPOiRaap5er8eAAQNw7NgxuafSZtiusuO+d+0iIyMRHR3N/Q/AvHnz8Mknn2DHjh3o3r271M79rWXN1c0Z7m+ARqNBr169EB8fj2XLlmHQoEFYuXKlx/czBiEf0Gg0iIuLg8FgsGs3GAxISkqSaVZtj8lkwpEjRxAZGSn3VNqMmJgYRERE2O17tbW1+Prrr7nvuej8+fM4depUu97/hBCYO3cuPvroI3z11VeIiYmxe5/7m3NXq5sz3N8cCSFgMpk8v595YCE3tcKmTZuEWq0Wb7/9tvjpp59EVlaW0Ov14sSJE3JPzW899dRTYufOneKXX34R+/btE/fcc48ICQlhza5QWVkpiouLRXFxsQAgli9fLoqLi8XJkyeFEEK89NJLIiwsTHz00Ufihx9+EFOnThWRkZHCaDTKPHN5tVS3yspK8dRTT4mioiJx/PhxsWPHDpGYmChuvPHGdl23xx9/XISFhYmdO3eKsrIy6ae6ulrqw/3N0dXqxv3NUU5Ojti1a5c4fvy4+P7778UzzzwjlEqlKCwsFEJ4dj9jEPKh1atXi+joaKHRaMTQoUPtLp0kR2lpaSIyMlKo1WrRrVs3MWnSJPH3v/9d7mn5nR07dggADj/Tp08XQtRf0vz888+LiIgIodVqxe233y5++OEHeSftB1qqW3V1tUhJSRFdunQRarVa9OjRQ0yfPl2UlpbKPW1ZOasXALFhwwapD/c3R1erG/c3R48++qj072WXLl3E2LFjpRAkhGf3M4UQQrhxhIqIiIiozeMaISIiImq3GISIiIio3WIQIiIionaLQYiIiIjaLQYhIiIiarcYhIiIiKjdYhAiIiKidotBiIioFRQKBT7++GO5p0FEHsYgRER+b8aMGVAoFA4/d911l9xTI6I2LkDuCRARtcZdd92FDRs22LVptVqZZkNE1wseESKiNkGr1SIiIsLup0OHDgDqT1utXbsWqampCAoKQkxMDD788EO7z//www+48847ERQUhE6dOmH27Nmoqqqy6/POO+/g1ltvhVarRWRkJObOnWv3fkVFBSZOnAidTofevXvjk08+8e5GE5HXMQgR0XXh2WefxQMPPIDDhw/jkUcewdSpU3HkyBEAQHV1Ne666y506NAB+/fvx4cffojt27fbBZ21a9dizpw5mD17Nn744Qd88skn6NWrl913LF68GFOmTMH333+P8ePH4+GHH8aFCxd8up1E5GGeeU4sEZH3TJ8+XahUKqHX6+1+lixZIoSof7p3RkaG3WdGjBghHn/8cSGEEOvXrxcdOnQQVVVV0vufffaZUCqVory8XAghRLdu3cSCBQuanQMAsXDhQul1VVWVUCgU4vPPP/fYdhKR73GNEBG1CWPGjMHatWvt2jp27Cj9PTEx0e69xMRElJSUAACOHDmCQYMGQa/XS++PHDkSVqsVP//8MxQKBc6cOYOxY8e2OIeBAwdKf9fr9QgJCcHZs2fd3SQi8gMMQkTUJuj1eodTVVejUCgAAEII6e/O+gQFBbVqPLVa7fBZq9Xq0pyIyL9wjRARXRf27dvn8Do2NhYA0K9fP5SUlODSpUvS+9988w2USiVuueUWhISEoGfPnvjyyy99Omcikh+PCBFRm2AymVBeXm7XFhAQgM6dOwMAPvzwQ8THx+O2227De++9h++++w5vv/02AODhhx/G888/j+nTp2PRokU4d+4c5s2bh/T0dISHhwMAFi1ahIyMDHTt2hWpqamorKzEN998g3nz5vl2Q4nIpxiEiKhN+OKLLxAZGWnX1qdPHxw9ehRA/RVdmzZtQmZmJiIiIvDee++hX79+AACdTodt27bhiSeewLBhw6DT6fDAAw9g+fLl0ljTp09HTU0NVqxYgaeffhqdO3fG5MmTfbeBRCQLhRBCyD0JIqJroVAosGXLFtx///1yT4WI2hiuESIiIqJ2i0GIiIiI2i2uESKiNo9n+InIXTwiRERERO0WgxARERG1WwxCRERE1G4xCBEREVG7xSBERERE7RaDEBEREbVbDEJERETUbjEIERERUbvFIERERETt1v8HLL2fRPQLULcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numEpochs = 30  # Adjust as needed\n",
    "losses = [] # To store avg loss per epoch\n",
    "\n",
    "for epoch in range(numEpochs):\n",
    "    model.train()\n",
    "    totalLoss = 0.0\n",
    "    for batch in trainLoader:\n",
    "        user = batch['user'].to(device)\n",
    "        beer = batch['beer'].to(device)\n",
    "        rating = batch['score'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user, beer)\n",
    "        loss = criterion(predictions, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        totalLoss += loss.item()\n",
    "    \n",
    "    avgLoss = totalLoss / len(trainLoader)\n",
    "    losses.append(avgLoss)\n",
    "    print(f\"Epoch {epoch+1}/{numEpochs}, Loss: {avgLoss:.4f}\")\n",
    "\n",
    "#for visualising the losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc66e3-1f30-49e8-a7c1-903341c9db2c",
   "metadata": {},
   "source": [
    "### Model Evaluation on Validation Set\n",
    "\n",
    "After training, the model was evaluated on the held-out **validation set** using the same MSE loss function. Evaluation was done in inference mode using `torch.no_grad()` to disable gradient computation and improve performance.\n",
    "\n",
    "#### Metrics:\n",
    "- **Mean Squared Error (MSE)**: Average of the squared differences between predicted and actual ratings.\n",
    "- **Root Mean Squared Error (RMSE)**: Square root of MSE, often used for interpretability in the original rating scale.\n",
    "\n",
    "#### Results:\n",
    "- **Validation MSE**: 0.0136\n",
    "- **Validation RMSE**: 0.1168\n",
    "\n",
    "These values suggest that the model is able to generalize well beyond the training data, with an average prediction error of ~0.117 on the normalized [0, 1] rating scale. This score-only collaborative filtering model now serves as a strong baseline before incorporating content features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0312334-838c-4acd-b1eb-c9cb8535c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.0136\n",
      "Validation RMSE: 0.1168\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "totalValLoss = 0.0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in valLoader:\n",
    "#         user = batch['user']\n",
    "#         beer = batch['beer']\n",
    "#         rating = batch['score']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in valLoader:\n",
    "        user = batch['user'].to(device)\n",
    "        beer = batch['beer'].to(device)\n",
    "        rating = batch['score'].to(device)\n",
    "\n",
    "        predictions = model(user, beer)\n",
    "        loss = criterion(predictions, rating)  # MSE loss\n",
    "        # Multiply by batch size to sum up total loss over the dataset\n",
    "        totalValLoss += loss.item() * rating.size(0)\n",
    "\n",
    "# Compute average MSE loss over the entire validation set\n",
    "avgValLoss = totalValLoss / len(valDataset)\n",
    "# RMSE is the square root of the MSE\n",
    "rmse = avgValLoss ** 0.5\n",
    "\n",
    "print(f\"Validation MSE: {avgValLoss:.4f}\")\n",
    "print(f\"Validation RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbafb2-b21f-44be-91f1-bd45d791308b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0add8-45a4-4b8e-9b2d-ddc0612d2486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2aa37b-847b-4a8b-9256-52ab84c78843",
   "metadata": {},
   "source": [
    "## Recommendation Utilities and Real vs Predicted Preferences\n",
    "\n",
    "This section establishes utility functions to interpret and evaluate the outputs of the trained collaborative filtering model, particularly for generating beer recommendations and validating them against real user preferences.\n",
    "\n",
    "---\n",
    "\n",
    "### Index Mappings\n",
    "\n",
    "Before making predictions or retrieving results, internal user and beer indices must be mapped back to their original forms:\n",
    "```python\n",
    "indexBeerDict = {index: beer for beer, index in beerIndexMap.items()}\n",
    "indexUserMap = {index: user for user, index in userIndexMap.items()}\n",
    "getUsername = lambda userIndex: indexUserMap.get(userIndex, \"Unknown User\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c69f10-8c74-4fb4-8ffd-d644d903439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions and datafames\n",
    "\n",
    "# inverse mappings\n",
    "indexBeerDict = {index: beer for beer, index in beerIndexMap.items()}\n",
    "indexUserMap = {index: user for user, index in userIndexMap.items()}\n",
    "\n",
    "getUsername = lambda userIndex: indexUserMap.get(userIndex, \"Unknown User\")\n",
    "\n",
    "def topKRecommendedBeersForUser(model, userIndex, topK=10):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tensor for all beer indices\n",
    "    allBeerIndices = torch.arange(len(beerIndexDict)).to(device)\n",
    "\n",
    "    # Tensor for users repeated for all beers\n",
    "    userTensor = torch.tensor([userIndex] * len(beerIndexDict), dtype=torch.long).to(device)\n",
    "    \n",
    "    # Get predictions for all beers for this user\n",
    "    with torch.no_grad():\n",
    "        predictedRatings = model(userTensor, allBeerIndices)\n",
    "\n",
    "    topRatings, topBeerIndices = torch.topk(predictedRatings, topK)\n",
    "\n",
    "    # Map the indices back to beer identifiers or names using indexBeerDict\n",
    "    recommendedBeers = [indexBeerDict[index.item()] for index in topBeerIndices]\n",
    "    \n",
    "    return recommendedBeers\n",
    "    \n",
    "beerDetails = df.groupby('beer_id').agg({\n",
    "    'name': 'first',\n",
    "    'state': 'first',\n",
    "    'country': 'first',\n",
    "    'style': 'first',\n",
    "    'availability': 'first',\n",
    "    'abv': 'mean',\n",
    "    'notes': 'first',\n",
    "    'look': 'mean',\n",
    "    'smell': 'mean',\n",
    "    'taste': 'mean',\n",
    "    'feel': 'mean',\n",
    "    'overall': 'mean',\n",
    "    'score': 'mean',\n",
    "    'name_brewery': 'first',\n",
    "    'city': 'first',\n",
    "    'notes_brewery': 'first',\n",
    "    'types': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "def getBeerDetailsFromIds(beerIdList):\n",
    "    df_idx = beerDetails.set_index('beer_id')\n",
    "    df_out = df_idx.loc[beerIdList]\n",
    "    return df_out.reset_index()\n",
    "\n",
    "def getActualTopKReviewedBeersForUser(username,topK=10):\n",
    "    userReviews = df[df['username'] == username]\n",
    "    return userReviews.sort_values(by='score', ascending=False).head(topK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f48137-ee7a-4f2a-a0c2-d214469a9e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username for user index 10: 86MonteSS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>style</th>\n",
       "      <th>availability</th>\n",
       "      <th>abv</th>\n",
       "      <th>notes</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>taste</th>\n",
       "      <th>feel</th>\n",
       "      <th>overall</th>\n",
       "      <th>score</th>\n",
       "      <th>name_brewery</th>\n",
       "      <th>city</th>\n",
       "      <th>notes_brewery</th>\n",
       "      <th>types</th>\n",
       "      <th>userIndex</th>\n",
       "      <th>beerIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388790</th>\n",
       "      <td>Trappistes Rochefort 10</td>\n",
       "      <td>Namur</td>\n",
       "      <td>BE</td>\n",
       "      <td>Belgian Quadrupel (Quad)</td>\n",
       "      <td>Year-round</td>\n",
       "      <td>11.3</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>645</td>\n",
       "      <td>86MonteSS</td>\n",
       "      <td>2003-04-21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>Brasserie de Rochefort</td>\n",
       "      <td>Rochefort</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>8180</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390655</th>\n",
       "      <td>Trappistes Rochefort 8</td>\n",
       "      <td>Namur</td>\n",
       "      <td>BE</td>\n",
       "      <td>Belgian Strong Dark Ale</td>\n",
       "      <td>Year-round</td>\n",
       "      <td>9.2</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>1696</td>\n",
       "      <td>86MonteSS</td>\n",
       "      <td>2003-05-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>Brasserie de Rochefort</td>\n",
       "      <td>Rochefort</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>8180</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412661</th>\n",
       "      <td>Abt 12</td>\n",
       "      <td>West Flanders</td>\n",
       "      <td>BE</td>\n",
       "      <td>Belgian Quadrupel (Quad)</td>\n",
       "      <td>Year-round</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>1708</td>\n",
       "      <td>86MonteSS</td>\n",
       "      <td>2003-11-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>Brouwerij St. Bernardus NV</td>\n",
       "      <td>Watou</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>Brewery</td>\n",
       "      <td>8180</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491497</th>\n",
       "      <td>Golden Monkey</td>\n",
       "      <td>PA</td>\n",
       "      <td>US</td>\n",
       "      <td>Belgian Tripel</td>\n",
       "      <td>Year-round</td>\n",
       "      <td>9.5</td>\n",
       "      <td>A magical, mystical Monkey whose golden sole g...</td>\n",
       "      <td>1003</td>\n",
       "      <td>86MonteSS</td>\n",
       "      <td>2003-10-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>Victory Brewing Company - Downingtown</td>\n",
       "      <td>Downingtown</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>Brewery, Bar, Eatery, Beer-to-go</td>\n",
       "      <td>8180</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369872</th>\n",
       "      <td>Imperial Stout</td>\n",
       "      <td>GB2</td>\n",
       "      <td>GB</td>\n",
       "      <td>Russian Imperial Stout</td>\n",
       "      <td>Year-round</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>782</td>\n",
       "      <td>86MonteSS</td>\n",
       "      <td>2003-04-21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>Samuel Smith Old Brewery (Tadcaster)</td>\n",
       "      <td>Tadcaster</td>\n",
       "      <td>No notes at this time.</td>\n",
       "      <td>Brewery, Beer-to-go</td>\n",
       "      <td>8180</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name          state country  \\\n",
       "388790  Trappistes Rochefort 10          Namur      BE   \n",
       "390655   Trappistes Rochefort 8          Namur      BE   \n",
       "412661                   Abt 12  West Flanders      BE   \n",
       "491497            Golden Monkey             PA      US   \n",
       "369872           Imperial Stout            GB2      GB   \n",
       "\n",
       "                           style availability   abv  \\\n",
       "388790  Belgian Quadrupel (Quad)   Year-round  11.3   \n",
       "390655   Belgian Strong Dark Ale   Year-round   9.2   \n",
       "412661  Belgian Quadrupel (Quad)   Year-round  10.0   \n",
       "491497            Belgian Tripel   Year-round   9.5   \n",
       "369872    Russian Imperial Stout   Year-round   7.0   \n",
       "\n",
       "                                                    notes  beer_id   username  \\\n",
       "388790                             No notes at this time.      645  86MonteSS   \n",
       "390655                             No notes at this time.     1696  86MonteSS   \n",
       "412661                             No notes at this time.     1708  86MonteSS   \n",
       "491497  A magical, mystical Monkey whose golden sole g...     1003  86MonteSS   \n",
       "369872                             No notes at this time.      782  86MonteSS   \n",
       "\n",
       "              date  ...  taste   feel  overall   score  \\\n",
       "388790  2003-04-21  ...  1.000  0.875    1.000  0.9800   \n",
       "390655  2003-05-16  ...  1.000  0.875    1.000  0.9800   \n",
       "412661  2003-11-06  ...  0.875  0.875    1.000  0.9375   \n",
       "491497  2003-10-07  ...  1.000  1.000    1.000  0.9250   \n",
       "369872  2003-04-21  ...  0.875  1.000    0.875  0.9250   \n",
       "\n",
       "                                 name_brewery         city  \\\n",
       "388790                 Brasserie de Rochefort    Rochefort   \n",
       "390655                 Brasserie de Rochefort    Rochefort   \n",
       "412661             Brouwerij St. Bernardus NV        Watou   \n",
       "491497  Victory Brewing Company - Downingtown  Downingtown   \n",
       "369872   Samuel Smith Old Brewery (Tadcaster)    Tadcaster   \n",
       "\n",
       "                 notes_brewery                             types userIndex  \\\n",
       "388790  No notes at this time.                           Brewery      8180   \n",
       "390655  No notes at this time.                           Brewery      8180   \n",
       "412661  No notes at this time.                           Brewery      8180   \n",
       "491497  No notes at this time.  Brewery, Bar, Eatery, Beer-to-go      8180   \n",
       "369872  No notes at this time.               Brewery, Beer-to-go      8180   \n",
       "\n",
       "       beerIndex  \n",
       "388790       307  \n",
       "390655       308  \n",
       "412661       324  \n",
       "491497       389  \n",
       "369872       291  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For a given user index get the actual top K reviewed beers:\n",
    "userIndex = 8180\n",
    "username = getUsername(userIndex)\n",
    "topK = 5\n",
    "print(f\"Username for user index {10}: {username}\")\n",
    "getActualTopKReviewedBeersForUser(username, topK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ffaac-70e1-4eb5-9a02-38454b75b7ef",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Insights\n",
    "\n",
    "- **Preference Profile**: The selected user (`86MonteSS`) consistently gives high ratings to strong, dark, and often Belgian-style beers such as Trappistes Rochefort 10 and Abt 12. This highlights a preference for high-ABV, full-bodied, and complex beers.\n",
    "\n",
    "- **Consistency in Taste**: All top-rated beers fall into either the Quadrupel, Tripel, or Imperial Stout categories, suggesting that taste preferences remain stable across styles that share richness, depth, and higher alcohol content.\n",
    "\n",
    "- **Metadata Utility**: The ability to aggregate and query detailed beer metadata enables clear interpretation of what the model is recommending and why. This provides transparency and supports explainability in the recommendation process.\n",
    "\n",
    "- **Validation Readiness**: These utilities allow for real-time comparison between model-generated recommendations and a user's historical top ratings. Such comparison is critical for iterative improvement of the recommender system.\n",
    "\n",
    "- **Future Direction**: Insights from user behavior and rating trends can be used to guide enhancements in hybrid modelsâ€”for example, by integrating beer features like style and ABV directly into the model architecture for personalized embeddings.\n",
    "\n",
    "- **Model Explainability**: This framework bridges machine-generated predictions and human-readable outputs, an essential component for user trust and system transparency in real-world recommender applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86461c3d-f99f-438f-9ac8-278084be291c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39262842-0b5a-478e-9878-3d31db69c5d2",
   "metadata": {},
   "source": [
    "### Conclusion: Vanilla Collaborative Filtering Model\n",
    "\n",
    "The initial collaborative filtering model, which uses only user and beer IDs along with learned embeddings and biases, demonstrated strong baseline performance in predicting beer ratings. The training process showed a consistent reduction in loss over 30 epochs, and the model achieved a low RMSE of **0.1168** on the validation setâ€”indicative of high predictive accuracy.\n",
    "\n",
    "Key strengths of the model include:\n",
    "- **Effective personalization** through embedding layers for both users and beers.\n",
    "- **Bias incorporation** at user, item, and global levels to capture rating tendencies.\n",
    "- **Scalable architecture** suitable for large datasets.\n",
    "\n",
    "However, the model has several limitations:\n",
    "- It **does not leverage content-based features** such as beer style, ABV, or textual reviews, which could enhance recommendations especially for new or sparsely rated items.\n",
    "- **Cold-start users or items** (those with few or no ratings) may receive poor recommendations due to lack of interaction history.\n",
    "- The model lacks interpretability and explainability, making it harder to justify predictions to end users.\n",
    "\n",
    "This vanilla model provides a solid foundation for collaborative filtering. In the next phase, we aim to incorporate **beer content features** into the model architecture to create a hybrid recommender system that can deliver even more accurate and robust recommendations across a wider range of users and items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9250da-3774-4320-8f6d-eaf3aa8baa09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn_course (GPU)",
   "language": "python",
   "name": "deeplearn_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
